{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tech Notes Tech Notes Run mkdocs to generate sites htmls Run mkdocs to generate sites htmls mkdocs build mkdocs serve # publish to git pages mkdocs gh-deploy It will be published on https://tanalex.github.io/tech_notes/","title":"Home"},{"location":"#tech-notes","text":"Tech Notes Run mkdocs to generate sites htmls","title":"Tech Notes"},{"location":"#run-mkdocs-to-generate-sites-htmls","text":"mkdocs build mkdocs serve # publish to git pages mkdocs gh-deploy It will be published on https://tanalex.github.io/tech_notes/","title":"Run mkdocs to generate sites htmls"},{"location":"DockerSwarm/","text":"Docker Swarm Stack with Traefik solution Docker Swarm Stack with Traefik solution Architect diagram High level explanation Traefik service act as load-balancer Frontier service example Backtier service example Steps to deploy and test Architect diagram High level explanation Lets say you have 8 VM Nodes showing as the Gray Box in the diagram above You plan to build a few fronttier web applications One web UI app written in TS or JS listening on port 5001 One Web REST API app writtern in DotNet Core listening on port 5002 One web GraphQL API app writtern in Javascript listening on port 5003 You want to use the following URL to access these services Web UI app: http://yourdomain.com/www REST API app: http://yourdomain.com/api GraphQL API app: http://yourdomain.com/graphql Traefik instance here can help, it works just like a reverse proxy. So based on a frontend rule like \"traefik.frontend.rule=PathPrefixStrip:/www , it will allow the request to be redirected/forwared to the backend service for the Web UI app This will be the same for backtier applications. You might want to run a few backtier app too One backend OSS app listening on port 60001 One backend Billing app listening on port 60002 One backend media app listing on port 60003 You want to access them from the fronttier containers using URL like these: Backend OSS app: http://backtier/oss/v1 Backend Billing app: http://backtier/billing/v1 Backend Media app: http://backtier/media/v1 Backend Media app version 2: http://backtier/media/v2 Now we need a 2nd Traefik instance to handle these ones Both of these 2 Traefik instances will listen on port 80 and 443, but only the fronttier Traefik instance docker container exposed/mapped to Node port 80 and 443, the backtier mapped to different ports or simply no need to map to Node Ports All the frontend containers can use http://backtier to access the backtier Traefik service anyway. Because we allow any container to deploy on any hosts to provide maximum flexibility, we will use a trick to differentiate which contains should be managed by which Traefik instance The way to achieve that is to use a tag on the Traefik service like \"--constraints=tag==traefik-fronttier\" All the containers with a tag like traefik-tags=traefik-fronttier will be associated only to the \"fronttier\" Traefik instance The same type of config works for backtier apps as well. Traefik service act as load-balancer There are 2 Traefik instances to handle both fronttier and backtier services Note: \"--constraints=tag==traefik-fronttier\" controls only the containers with traefik-tags=traefik-fronttier tags will be controlled by the fronttier traefik controller \"--constraints=tag==traefik-backtier\" controls only the containers with traefik-tags=traefik-backtier tags will be controlled by the backtier traefik controller restart_policy set to condition: any will allow these 2 traefik container/service to auto restart after node reboot or docker daemon reboot. constraints: [node.role == manager] will force these 2 traefik services to run only on Swarm Manager role nodes version: '3.3' networks: frontend: driver: overlay attachable: true volumes: data: services: fronttier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-fronttier\" - \"--web\" ports: - \"80:80\" # The HTTP port - \"443:443\" - \"8000:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: #condition: on-failure condition: any backtier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-backtier\" - \"--web\" - \"--loglevel=DEBUG\" ports: - \"7180:80\" # The HTTP port - \"7443:443\" - \"7880:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: condition: any Frontier service example The following simulate a simple fronttier webapp Note: extra_hosts are the list of the hosts Docker will put them into the container's /etc/hosts file This sample lists external IP for the redis , mongodb and consul services. extra_hosts will allow apps in docker container to communicate to external services constraints: - node.role == worker set the service contains to run only in nodes whose role is a worker - \"traefik.basic.port=5000\" this is the port for our webapp:1.1 service. This webapp listens and exposes on port 5000 - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" this is Traefik setting for URL mapping. Any request to /webapp will be forwarded to port 5000 (the webapp service itself) \"traefik.backend=webapp\" set the name of the service Traefik will forward the request to, which is the service itself - \"traefik.docker.network=okto_frontend\" this is the Docker overlay network which Traefik and all services use to communicate - \"traefik.tags=traefik-fronttier\" is to set the webapp service to associate with the traefik-fronttier Traefik instance version: \"3.3\" services: webapp: image: devmr1oktodock1:5000/webapp:1.1 extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=5000\" - \"traefik.basic.protocol=http\" - \"traefik.backend=webapp\" - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-fronttier\" Backtier service example whoami: image: devmr1oktodock1:5000/whoami:latest extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=80\" - \"traefik.basic.protocol=http\" - \"traefik.backend=whoami\" - \"traefik.frontend.rule=PathPrefixStrip:/whoami\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-backtier\" networks: frontend: driver: overlay attachable: true Steps to deploy and test #Run this to deploy docker stack deploy -c docker-traefik-without-local-volumn.yml okto #Check if 2 instance's API interface (it was started using the --web flag in the yml) curl --noproxy '*' http://devmr1oktodock1:8000/api curl --noproxy '*' http://devmr1oktodock1:7880/api Once these 2 Traefik instances are running well, deploy both fronttier and backtier apps #Run this to deploy docker stack deploy -c docker-webapp.yml okto #Check the services curl --noproxy '*' http://devmr1oktodock1/webapp curl --noproxy '*' http://devmr1oktodock1:7180/whoami The following commands will scale the services to run multiple instances then check their status [root@devmr1oktodock1 multiple-traefik-stack]# docker service scale okto_webapp=3 okto_webapp scaled to 3 overall progress: 3 out of 3 tasks 1/3: running [==================================================>] 2/3: running [==================================================>] 3/3: running [==================================================>] verify: Service converged [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ldae6tup6v8s okto_webapp.1 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 37 minutes ago etexcwod5tux okto_webapp.2 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago klopqgsbw2pe okto_webapp.3 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_whoami ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ojzt1rgpxx4i okto_whoami.1 devmr1oktodock1:5000/whoami:latest devmr1oktodock2.br.devrep.tv.telus.net Running Running 10 minutes ago ji9aga2xq4e0 okto_whoami.2 devmr1oktodock1:5000/whoami:latest devmr1oktodock1.br.devrep.tv.telus.net Running Running 9 minutes ago jbnkom5oiv2a okto_whoami.3 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago ww7315qshpzd okto_whoami.4 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago","title":"DockerSwarm"},{"location":"DockerSwarm/#docker-swarm-stack-with-traefik-solution","text":"Docker Swarm Stack with Traefik solution Architect diagram High level explanation Traefik service act as load-balancer Frontier service example Backtier service example Steps to deploy and test","title":"Docker Swarm Stack with Traefik solution"},{"location":"DockerSwarm/#architect-diagram","text":"","title":"Architect diagram"},{"location":"DockerSwarm/#high-level-explanation","text":"Lets say you have 8 VM Nodes showing as the Gray Box in the diagram above You plan to build a few fronttier web applications One web UI app written in TS or JS listening on port 5001 One Web REST API app writtern in DotNet Core listening on port 5002 One web GraphQL API app writtern in Javascript listening on port 5003 You want to use the following URL to access these services Web UI app: http://yourdomain.com/www REST API app: http://yourdomain.com/api GraphQL API app: http://yourdomain.com/graphql Traefik instance here can help, it works just like a reverse proxy. So based on a frontend rule like \"traefik.frontend.rule=PathPrefixStrip:/www , it will allow the request to be redirected/forwared to the backend service for the Web UI app This will be the same for backtier applications. You might want to run a few backtier app too One backend OSS app listening on port 60001 One backend Billing app listening on port 60002 One backend media app listing on port 60003 You want to access them from the fronttier containers using URL like these: Backend OSS app: http://backtier/oss/v1 Backend Billing app: http://backtier/billing/v1 Backend Media app: http://backtier/media/v1 Backend Media app version 2: http://backtier/media/v2 Now we need a 2nd Traefik instance to handle these ones Both of these 2 Traefik instances will listen on port 80 and 443, but only the fronttier Traefik instance docker container exposed/mapped to Node port 80 and 443, the backtier mapped to different ports or simply no need to map to Node Ports All the frontend containers can use http://backtier to access the backtier Traefik service anyway. Because we allow any container to deploy on any hosts to provide maximum flexibility, we will use a trick to differentiate which contains should be managed by which Traefik instance The way to achieve that is to use a tag on the Traefik service like \"--constraints=tag==traefik-fronttier\" All the containers with a tag like traefik-tags=traefik-fronttier will be associated only to the \"fronttier\" Traefik instance The same type of config works for backtier apps as well.","title":"High level explanation"},{"location":"DockerSwarm/#traefik-service-act-as-load-balancer","text":"There are 2 Traefik instances to handle both fronttier and backtier services Note: \"--constraints=tag==traefik-fronttier\" controls only the containers with traefik-tags=traefik-fronttier tags will be controlled by the fronttier traefik controller \"--constraints=tag==traefik-backtier\" controls only the containers with traefik-tags=traefik-backtier tags will be controlled by the backtier traefik controller restart_policy set to condition: any will allow these 2 traefik container/service to auto restart after node reboot or docker daemon reboot. constraints: [node.role == manager] will force these 2 traefik services to run only on Swarm Manager role nodes version: '3.3' networks: frontend: driver: overlay attachable: true volumes: data: services: fronttier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-fronttier\" - \"--web\" ports: - \"80:80\" # The HTTP port - \"443:443\" - \"8000:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: #condition: on-failure condition: any backtier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-backtier\" - \"--web\" - \"--loglevel=DEBUG\" ports: - \"7180:80\" # The HTTP port - \"7443:443\" - \"7880:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: condition: any","title":"Traefik service act as load-balancer"},{"location":"DockerSwarm/#frontier-service-example","text":"The following simulate a simple fronttier webapp Note: extra_hosts are the list of the hosts Docker will put them into the container's /etc/hosts file This sample lists external IP for the redis , mongodb and consul services. extra_hosts will allow apps in docker container to communicate to external services constraints: - node.role == worker set the service contains to run only in nodes whose role is a worker - \"traefik.basic.port=5000\" this is the port for our webapp:1.1 service. This webapp listens and exposes on port 5000 - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" this is Traefik setting for URL mapping. Any request to /webapp will be forwarded to port 5000 (the webapp service itself) \"traefik.backend=webapp\" set the name of the service Traefik will forward the request to, which is the service itself - \"traefik.docker.network=okto_frontend\" this is the Docker overlay network which Traefik and all services use to communicate - \"traefik.tags=traefik-fronttier\" is to set the webapp service to associate with the traefik-fronttier Traefik instance version: \"3.3\" services: webapp: image: devmr1oktodock1:5000/webapp:1.1 extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=5000\" - \"traefik.basic.protocol=http\" - \"traefik.backend=webapp\" - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-fronttier\"","title":"Frontier service example"},{"location":"DockerSwarm/#backtier-service-example","text":"whoami: image: devmr1oktodock1:5000/whoami:latest extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=80\" - \"traefik.basic.protocol=http\" - \"traefik.backend=whoami\" - \"traefik.frontend.rule=PathPrefixStrip:/whoami\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-backtier\" networks: frontend: driver: overlay attachable: true","title":"Backtier service example"},{"location":"DockerSwarm/#steps-to-deploy-and-test","text":"#Run this to deploy docker stack deploy -c docker-traefik-without-local-volumn.yml okto #Check if 2 instance's API interface (it was started using the --web flag in the yml) curl --noproxy '*' http://devmr1oktodock1:8000/api curl --noproxy '*' http://devmr1oktodock1:7880/api Once these 2 Traefik instances are running well, deploy both fronttier and backtier apps #Run this to deploy docker stack deploy -c docker-webapp.yml okto #Check the services curl --noproxy '*' http://devmr1oktodock1/webapp curl --noproxy '*' http://devmr1oktodock1:7180/whoami The following commands will scale the services to run multiple instances then check their status [root@devmr1oktodock1 multiple-traefik-stack]# docker service scale okto_webapp=3 okto_webapp scaled to 3 overall progress: 3 out of 3 tasks 1/3: running [==================================================>] 2/3: running [==================================================>] 3/3: running [==================================================>] verify: Service converged [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ldae6tup6v8s okto_webapp.1 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 37 minutes ago etexcwod5tux okto_webapp.2 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago klopqgsbw2pe okto_webapp.3 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_whoami ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ojzt1rgpxx4i okto_whoami.1 devmr1oktodock1:5000/whoami:latest devmr1oktodock2.br.devrep.tv.telus.net Running Running 10 minutes ago ji9aga2xq4e0 okto_whoami.2 devmr1oktodock1:5000/whoami:latest devmr1oktodock1.br.devrep.tv.telus.net Running Running 9 minutes ago jbnkom5oiv2a okto_whoami.3 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago ww7315qshpzd okto_whoami.4 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago","title":"Steps to deploy and test"},{"location":"Kubernetes/KubernetesNotes/","text":"Notes","title":"Kubernetes"},{"location":"Kubernetes/KubernetesNotes/#notes","text":"","title":"Notes"},{"location":"Powershell/","text":"Powershell Note Powershell Note Awsome Powershell and other useful sites [Powershell Modules Note](Module.md) [Powershell Functions](Functions.md) Awsome Powershell and other useful sites Awsome Powershell PlatyPS generate module help in Markdown Powershell Modules Note Powershell Functions","title":"Powershell Note"},{"location":"Powershell/#powershell-note","text":"Powershell Note Awsome Powershell and other useful sites [Powershell Modules Note](Module.md) [Powershell Functions](Functions.md)","title":"Powershell Note"},{"location":"Powershell/#awsome-powershell-and-other-useful-sites","text":"Awsome Powershell PlatyPS generate module help in Markdown","title":"Awsome Powershell and other useful sites"},{"location":"Powershell/#powershell-modules-note","text":"","title":"Powershell Modules Note"},{"location":"Powershell/#powershell-functions","text":"","title":"Powershell Functions"},{"location":"Powershell/Functions/","text":"Powershell functions notes Powershell functions notes ParameterSet and CmdletBinding Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments Function help doc string ParameterSet and CmdletBinding Notable points: DefaultParameterSetName [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] [ValidatePattern('^*$|^none$|^.+$')] [ValidateSet('open', 'closed')] Use [string[]] to indicate it's a string array @() [AllowNull()] function Get-GitHubIssues { [CmdletBinding(DefaultParameterSetName='repo')] param( [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] [string] $Owner = $null, [Parameter(Mandatory = $false, Position=1, ParameterSetName='repo')] [string] $Repository = $null, [Parameter(Mandatory = $false, ParameterSetName='user')] [switch] $ForUser, [Parameter(Mandatory = $false)] [ValidateSet('open', 'closed')] $State = 'open', [Parameter(Mandatory = $false, ParameterSetName='user')] [ValidateSet('assigned', 'created', 'mentioned', 'subscribed')] $Filter = 'assigned', [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^\\d+$')] $Milestone, [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^.+$')] $Assignee, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Creator, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Mentioned, [Parameter(Mandatory = $false)] [string[]] $Labels = @(), [Parameter(Mandatory = $false)] [ValidateSet('created', 'updated', 'comments')] $Sort = 'created', [Parameter(Mandatory = $false)] [ValidateSet('asc', 'desc')] $Direction = 'desc', [Parameter(Mandatory = $false)] [DateTime] [AllowNull()] #Optional string of a timestamp in ISO 8601 format: YYYY-MM-DDTHH:MM:SSZ $Since ) Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments Note [Alias( 'Instance', 'Instances', 'ServerInstance')] [ValidateNotNullOrEmpty()] [Switch] [OutputType([System.Data.SQLite.SQLiteConnection])] [cmdletbinding()] [OutputType([System.Data.SQLite.SQLiteConnection])] param( [Parameter( Position=0, Mandatory=$true, ValueFromPipeline=$true, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false, HelpMessage='SQL Server Instance required...' )] [Alias( 'Instance', 'Instances', 'ServerInstance', 'Server', 'Servers','cn','Path','File','FullName','Database' )] [ValidateNotNullOrEmpty()] [string[]] $DataSource, [Parameter( Position=2, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [System.Security.SecureString] $Password, [Parameter( Position=3, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [Switch] $ReadOnly, [Parameter( Position=4, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [bool] $Open = $True ) Function help doc string function Out-DataTable { <# .SYNOPSIS Creates a DataTable for an object .DESCRIPTION Creates a DataTable based on an object's properties. .PARAMETER InputObject One or more objects to convert into a DataTable .PARAMETER NonNullable A list of columns to set disable AllowDBNull on .INPUTS Object Any object can be piped to Out-DataTable .OUTPUTS System.Data.DataTable .EXAMPLE $dt = Get-psdrive | Out-DataTable # This example creates a DataTable from the properties of Get-psdrive and assigns output to $dt variable .EXAMPLE Get-Process | Select Name, CPU | Out-DataTable | Invoke-SQLBulkCopy -ServerInstance $SQLInstance -Database $Database -Table $SQLTable -force -verbose # Get a list of processes and their CPU, create a datatable, bulk import that data .NOTES Adapted from script by Marc van Orsouw and function from Chad Miller Version History v1.0 - Chad Miller - Initial Release v1.1 - Chad Miller - Fixed Issue with Properties v1.2 - Chad Miller - Added setting column datatype by property as suggested by emp0 v1.3 - Chad Miller - Corrected issue with setting datatype on empty properties v1.4 - Chad Miller - Corrected issue with DBNull v1.5 - Chad Miller - Updated example v1.6 - Chad Miller - Added column datatype logic with default to string v1.7 - Chad Miller - Fixed issue with IsArray v1.8 - ramblingcookiemonster - Removed if($Value) logic. This would not catch empty strings, zero, $false and other non-null items - Added perhaps pointless error handling .LINK https://github.com/RamblingCookieMonster/PowerShell .LINK Invoke-SQLBulkCopy .LINK Invoke-Sqlcmd2 .LINK New-SQLConnection .FUNCTIONALITY SQL #>","title":"PS Functions Note"},{"location":"Powershell/Functions/#powershell-functions-notes","text":"Powershell functions notes ParameterSet and CmdletBinding Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments Function help doc string","title":"Powershell functions notes"},{"location":"Powershell/Functions/#parameterset-and-cmdletbinding","text":"Notable points: DefaultParameterSetName [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] [ValidatePattern('^*$|^none$|^.+$')] [ValidateSet('open', 'closed')] Use [string[]] to indicate it's a string array @() [AllowNull()] function Get-GitHubIssues { [CmdletBinding(DefaultParameterSetName='repo')] param( [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] [string] $Owner = $null, [Parameter(Mandatory = $false, Position=1, ParameterSetName='repo')] [string] $Repository = $null, [Parameter(Mandatory = $false, ParameterSetName='user')] [switch] $ForUser, [Parameter(Mandatory = $false)] [ValidateSet('open', 'closed')] $State = 'open', [Parameter(Mandatory = $false, ParameterSetName='user')] [ValidateSet('assigned', 'created', 'mentioned', 'subscribed')] $Filter = 'assigned', [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^\\d+$')] $Milestone, [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^.+$')] $Assignee, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Creator, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Mentioned, [Parameter(Mandatory = $false)] [string[]] $Labels = @(), [Parameter(Mandatory = $false)] [ValidateSet('created', 'updated', 'comments')] $Sort = 'created', [Parameter(Mandatory = $false)] [ValidateSet('asc', 'desc')] $Direction = 'desc', [Parameter(Mandatory = $false)] [DateTime] [AllowNull()] #Optional string of a timestamp in ISO 8601 format: YYYY-MM-DDTHH:MM:SSZ $Since )","title":"ParameterSet and CmdletBinding"},{"location":"Powershell/Functions/#use-helpmessage-alias-valuefrompipelinebypropertyname-valuefromremainingarguments","text":"Note [Alias( 'Instance', 'Instances', 'ServerInstance')] [ValidateNotNullOrEmpty()] [Switch] [OutputType([System.Data.SQLite.SQLiteConnection])] [cmdletbinding()] [OutputType([System.Data.SQLite.SQLiteConnection])] param( [Parameter( Position=0, Mandatory=$true, ValueFromPipeline=$true, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false, HelpMessage='SQL Server Instance required...' )] [Alias( 'Instance', 'Instances', 'ServerInstance', 'Server', 'Servers','cn','Path','File','FullName','Database' )] [ValidateNotNullOrEmpty()] [string[]] $DataSource, [Parameter( Position=2, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [System.Security.SecureString] $Password, [Parameter( Position=3, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [Switch] $ReadOnly, [Parameter( Position=4, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [bool] $Open = $True )","title":"Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments"},{"location":"Powershell/Functions/#function-help-doc-string","text":"function Out-DataTable { <# .SYNOPSIS Creates a DataTable for an object .DESCRIPTION Creates a DataTable based on an object's properties. .PARAMETER InputObject One or more objects to convert into a DataTable .PARAMETER NonNullable A list of columns to set disable AllowDBNull on .INPUTS Object Any object can be piped to Out-DataTable .OUTPUTS System.Data.DataTable .EXAMPLE $dt = Get-psdrive | Out-DataTable # This example creates a DataTable from the properties of Get-psdrive and assigns output to $dt variable .EXAMPLE Get-Process | Select Name, CPU | Out-DataTable | Invoke-SQLBulkCopy -ServerInstance $SQLInstance -Database $Database -Table $SQLTable -force -verbose # Get a list of processes and their CPU, create a datatable, bulk import that data .NOTES Adapted from script by Marc van Orsouw and function from Chad Miller Version History v1.0 - Chad Miller - Initial Release v1.1 - Chad Miller - Fixed Issue with Properties v1.2 - Chad Miller - Added setting column datatype by property as suggested by emp0 v1.3 - Chad Miller - Corrected issue with setting datatype on empty properties v1.4 - Chad Miller - Corrected issue with DBNull v1.5 - Chad Miller - Updated example v1.6 - Chad Miller - Added column datatype logic with default to string v1.7 - Chad Miller - Fixed issue with IsArray v1.8 - ramblingcookiemonster - Removed if($Value) logic. This would not catch empty strings, zero, $false and other non-null items - Added perhaps pointless error handling .LINK https://github.com/RamblingCookieMonster/PowerShell .LINK Invoke-SQLBulkCopy .LINK Invoke-Sqlcmd2 .LINK New-SQLConnection .FUNCTIONALITY SQL #>","title":"Function help doc string"},{"location":"Powershell/Module/","text":"PS Modules Use Set-Alias to link function in module to a script Typically, functions are in the psm1 file but you can write in regular script files then use Set-Alias to link them in the psm1 module file Set-Alias -Name Build-Checkpoint -Value (Join-Path $PSScriptRoot Build-Checkpoint.ps1) Set-Alias -Name Build-Parallel -Value (Join-Path $PSScriptRoot Build-Parallel.ps1) Set-Alias -Name Invoke-Build -Value (Join-Path $PSScriptRoot Invoke-Build.ps1) Export-ModuleMember -Alias Build-Checkpoint, Build-Parallel, Invoke-Build Import all function scripts in a folder This snipet is from PSSlack.psm1 #Get public and private function definition files. $Public = @( Get-ChildItem -Path $PSScriptRoot\\Public\\*.ps1 -ErrorAction SilentlyContinue ) $Private = @( Get-ChildItem -Path $PSScriptRoot\\Private\\*.ps1 -ErrorAction SilentlyContinue ) $ModuleRoot = $PSScriptRoot #Dot source the files Foreach($import in @($Public + $Private)) { Try { . $import.fullname } Catch { Write-Error -Message \"Failed to import function $($import.fullname): $_\" } } Beginning in PowerShell 3.0, there is a new automatic variable available called $PSScriptRoot. This variable previously was only available within modules. It always points to the folder the current script is located in (so it only starts to be useful once you actually save a script before you run it). You can use $PSScriptRoot to load additional resources relative to your script location. For example, if you decide to place some functions in a separate \"library\" script that is located in the same folder, this would load the library script and import all of its functions The following snipet handles PS v2 situation #handle PS2 if(-not $PSScriptRoot) { $PSScriptRoot = Split-Path $MyInvocation.MyCommand.Path -Parent } Export functions # $Public is an array imported above Export-ModuleMember -Function $Public.Basename -Variable _PSSlackColorMap Export using wild-cards Export-ModuleMember -Function 'Get-*' Powershell will auto convert array to string with comma Export-ModuleMember -Function @($Public + $Private)) Export-ModuleMember -Function New-GitHubOAuthToken, New-GitHubPullRequest, Get-GitHubIssues, Get-GitHubEvents, Get-GitHubRepositories, ... ... Check if the script is called by Dot Source or by Module (psm1) # if it's not dot sourced, call the function # Note: $args is an array, in order to pass them to function # need to convert that array to a space separated string if ( $MyInvocation.InvocationName -ne '.' -AND $MyInvocation.Line -ne '' ){ Okto-UsersGet ($args[1..$($args.Length-1)] -join \" \") } #Check if it's called by psm1 module if ($MyInvocation.MyCommand.Name.EndsWith('.psm1')){ Export-ModuleMember -Function \"Set-Okto-Login\" }","title":"PS Modules Note"},{"location":"Powershell/Module/#ps-modules","text":"","title":"PS Modules"},{"location":"Powershell/Module/#use-set-alias-to-link-function-in-module-to-a-script","text":"Typically, functions are in the psm1 file but you can write in regular script files then use Set-Alias to link them in the psm1 module file Set-Alias -Name Build-Checkpoint -Value (Join-Path $PSScriptRoot Build-Checkpoint.ps1) Set-Alias -Name Build-Parallel -Value (Join-Path $PSScriptRoot Build-Parallel.ps1) Set-Alias -Name Invoke-Build -Value (Join-Path $PSScriptRoot Invoke-Build.ps1) Export-ModuleMember -Alias Build-Checkpoint, Build-Parallel, Invoke-Build","title":"Use Set-Alias to link function in module to a script"},{"location":"Powershell/Module/#import-all-function-scripts-in-a-folder","text":"This snipet is from PSSlack.psm1 #Get public and private function definition files. $Public = @( Get-ChildItem -Path $PSScriptRoot\\Public\\*.ps1 -ErrorAction SilentlyContinue ) $Private = @( Get-ChildItem -Path $PSScriptRoot\\Private\\*.ps1 -ErrorAction SilentlyContinue ) $ModuleRoot = $PSScriptRoot #Dot source the files Foreach($import in @($Public + $Private)) { Try { . $import.fullname } Catch { Write-Error -Message \"Failed to import function $($import.fullname): $_\" } } Beginning in PowerShell 3.0, there is a new automatic variable available called $PSScriptRoot. This variable previously was only available within modules. It always points to the folder the current script is located in (so it only starts to be useful once you actually save a script before you run it). You can use $PSScriptRoot to load additional resources relative to your script location. For example, if you decide to place some functions in a separate \"library\" script that is located in the same folder, this would load the library script and import all of its functions The following snipet handles PS v2 situation #handle PS2 if(-not $PSScriptRoot) { $PSScriptRoot = Split-Path $MyInvocation.MyCommand.Path -Parent }","title":"Import all function scripts in a folder"},{"location":"Powershell/Module/#export-functions","text":"# $Public is an array imported above Export-ModuleMember -Function $Public.Basename -Variable _PSSlackColorMap Export using wild-cards Export-ModuleMember -Function 'Get-*' Powershell will auto convert array to string with comma Export-ModuleMember -Function @($Public + $Private)) Export-ModuleMember -Function New-GitHubOAuthToken, New-GitHubPullRequest, Get-GitHubIssues, Get-GitHubEvents, Get-GitHubRepositories, ... ...","title":"Export functions"},{"location":"Powershell/Module/#check-if-the-script-is-called-by-dot-source-or-by-module-psm1","text":"# if it's not dot sourced, call the function # Note: $args is an array, in order to pass them to function # need to convert that array to a space separated string if ( $MyInvocation.InvocationName -ne '.' -AND $MyInvocation.Line -ne '' ){ Okto-UsersGet ($args[1..$($args.Length-1)] -join \" \") } #Check if it's called by psm1 module if ($MyInvocation.MyCommand.Name.EndsWith('.psm1')){ Export-ModuleMember -Function \"Set-Okto-Login\" }","title":"Check if the script is called by Dot Source or by Module (psm1)"},{"location":"Powershell/Snippets/","text":"Common PS Snippets Common PS Snippets Select-String Convert between Secure Password and Plain Password Write-Debug, Write-Verbose, Write-Error and Out-String Create a C# function and populate PSObject in the function Use switch statement Use switch to check PsCmdlet.ParameterSet Use Invoke-RestMethod to get GitHubOAuth Token Use try catch and get the error using $Error[0] Detect 64bit or 32bit then add DLL Use slect (select-object) to add a new property Environment variables Select-String Perform a case sensitive matching of literal strings: PS C:\\> \"Hello\",\"HELLO\" | select-string -pattern \"HELLO\" -casesensitive Search through all files with the .xml file extension in the current directory and display the lines in those files that include the case sensitive string \"Princess\": PS C:\\> select-string -path *.xml -pattern \"Princess\" -casesensitive Retrieve the last 100 events from the application event log and filter to show only those containing the message string \"failed\": PS C:\\> $events = get-eventlog -logname application -newest 100 PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" Now include 2 lines before and 3 lines after each matching line - line numbers will appear in the output with a > prefixing the matching line: PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" -Context 2,3 Examine all files in the subdirectories of C:\\Windows\\System32 with the .txt file name extension and search for the Case-Sensitive string \"Microsoft\": PS C:\\> get-childitem c:\\windows\\system32\\* -include *.txt -recurse | select-string -pattern \"Microsoft\" -casesensitive Select lines from a file containing \"Total Sales\" and then split the matching lines: PS C:\\> $demo = get-content C:\\demo\\sales.txt PS C:\\> $demo | select-string \"Total Sales\" | %{$_.line.split()} Convert between Secure Password and Plain Password if ($Password) { $BSTR = [System.Runtime.InteropServices.Marshal]::SecureStringToBSTR($Password) $PlainPassword = [System.Runtime.InteropServices.Marshal]::PtrToStringAuto($BSTR) $ConnectionString += \"Password=$PlainPassword;\" } Write-Debug, Write-Verbose, Write-Error and Out-String Try { $conn.Open() } Catch { Write-Error $_ continue } Write-Debug \"ConnectionString $ConnectionString\" Write-Verbose \"Created SQLiteConnection:`n$($Conn | Out-String)\" Create a C# function and populate PSObject in the function If($As -eq \"PSObject\") { #This code scrubs DBNulls. Props to Dave Wyatt $cSharp = @' using System; using System.Data; using System.Management.Automation; public class DBNullScrubber { public static PSObject DataRowToPSObject(DataRow row) { PSObject psObject = new PSObject(); if (row != null && (row.RowState & DataRowState.Detached) != DataRowState.Detached) { foreach (DataColumn column in row.Table.Columns) { Object value = null; if (!row.IsNull(column)) { value = row[column]; } psObject.Properties.Add(new PSNoteProperty(column.ColumnName, value)); } } return psObject; } } '@ Try { Add-Type -TypeDefinition $cSharp -ReferencedAssemblies 'System.Data','System.Xml' -ErrorAction stop } Catch { If(-not $_.ToString() -like \"*The type name 'DBNullScrubber' already exists*\") { Write-Warning \"Could not load DBNullScrubber. Defaulting to DataRow output: $_\" $As = \"Datarow\" } } } To use the new class and function foreach ($row in $ds.Tables[0].Rows) { [DBNullScrubber]::DataRowToPSObject($row) } Use switch statement First block is a string or Default or a condition block switch ($ErrorActionPreference.tostring()) { {'SilentlyContinue','Ignore' -contains $_} {} 'Stop' { Throw $Err } 'Continue' { Write-Error $Err} Default { Write-Error $Err} } Use switch to check PsCmdlet.ParameterSet Note [string]::IsNullOrEmpty use throw \"Error message\" to throw an error For long lines, use ` to continue lines switch ($PsCmdlet.ParameterSetName) { 'repo' { $missingOwner = [string]::IsNullOrEmpty($Owner) $missingRepo = [string]::IsNullOrEmpty($Repository) if ($missingOwner -and $missingRepo) { $remotes = GetRemotes #first remote in order here wins! 'upstream', 'origin' | % { if ([string]::IsNullOrEmpty($Owner) -and $remotes.$_) { $Owner = $remotes.$_.owner $Repository = $remotes.$_.repository Write-Host \"Found $_ remote with owner $Owner\" } } ... ... throw \"An Owner and Repository must be specified together\" } # accept null or lower case if ($Milestone) { $Milestone = $Milestone.ToLower() } GetRepoIssues $Owner $Repository $Milestone $State.ToLower() ` $Assignee $Creator $Mentioned $Labels $Sort.ToLower() ` $Direction.ToLower() $PsBoundParameters.Since } 'user' { if ([string]::IsNullOrEmpty($Env:GITHUB_OAUTH_TOKEN)) { throw \"Set GITHUB_OAUTH_TOKEN env variable \"} GetUserIssues $Filter.ToLower() $State.ToLower() $Labels ` $Sort.ToLower() $Direction.ToLower() $PsBoundParameters.Since } } Use Invoke-RestMethod to get GitHubOAuth Token it's using basic auth, use GetBytes to convert string to bytes then use ToBase64String to convert them to base64 string function Get-GitHubOAuthTokens { [CmdletBinding()] param( [Parameter(Mandatory = $true)] [string] $UserName, [Parameter(Mandatory = $true)] [string] $Password ) try { $params = @{ Uri = 'https://api.github.com/authorizations'; Headers = @{ Authorization = 'Basic ' + [Convert]::ToBase64String( [Text.Encoding]::ASCII.GetBytes(\"$($userName):$($password)\")); } } $global:GITHUB_API_OUTPUT = Invoke-RestMethod @params #Write-Verbose $global:GITHUB_API_OUTPUT $global:GITHUB_API_OUTPUT | % { $date = [DateTime]::Parse($_.created_at).ToString('g') Write-Host \"`n$($_.app.name) - Created $date\" Write-Host \"`t$($_.token)`n`t$($_.app.url)\" } } catch { Write-Error \"An unexpected error occurred (bad user/password?) $($Error[0])\" } } Use try catch and get the error using $Error[0] catch { Write-Error \"An unexpected error occurred $($Error[0])\" } Detect 64bit or 32bit then add DLL #Pick and import assemblies: if([IntPtr]::size -eq 8) #64 { $SQLiteAssembly = Join-path $PSScriptRoot \"x64\\System.Data.SQLite.dll\" } elseif([IntPtr]::size -eq 4) #32 { $SQLiteAssembly = Join-path $PSScriptRoot \"x86\\System.Data.SQLite.dll\" } else { Throw \"Something is odd with bitness...\" } if( -not ($Library = Add-Type -path $SQLiteAssembly -PassThru -ErrorAction stop) ) { Throw \"This module requires the ADO.NET driver for SQLite:`n`thttp://system.data.sqlite.org/index.html/doc/trunk/www/downloads.wiki\" } Use slect (select-object) to add a new property get-process| select ProcessName, @{ Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} | select -First 4 ProcessName Start Day ----------- --------- AccelerometerSt Sunday AcroRd32 Monday AcroRd32 Monday Adobe CEF Helper Sunday Display only the name, ID and Working Set(WS) properties of Get-Process: PS C:\\> get-process | select-object ProcessName,Id,WS Display only the Name and modules properties of Get-Process, use -ExpandProperty to display the details contained within the modules property: PS C:\\> get-process | select-object ProcessName -expandproperty modules | format-list Display the 5 processes that are using the most memory (WS=Working Set): PS C:\\> get-process | sort-object -property WS | select-object -Last 5 Display the name and claculate the start day of the processes running: PS C:\\> get-process | select-object ProcessName,@{Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} Get the first (newest) and last (oldest) events in the Windows PowerShell event log: PS C:\\> $evts = get-eventlog -log \"Windows PowerShell\" PS C:\\> $evts | select-object -index 0, ($evts.count - 1) Retrieve all the names listed in the Servers.txt file, except for the first one: PS C:\\> get-content servers.txt | select-object -skip 1 Environment variables powershell gci env: # list environment variables dir env: # or gci env: # show env vars whose name contains \u201cpath\u201d Get-ChildItem Env:*path* | format-list # show value of \u201cpath\u201d $env:path Set or Remove # sets a env var named myX for current session $env:myX = \"alice\" # get value of a env var $env:myX # deleting a env var from the current session Remove-Item env:myX # adding path to the path env var $env:path = $env:path + \";C:\\Program Files (x86)\\ErgoEmacs\\hunspell\" View/Set Permament Environment Variables Permanent env vars are stored in Windows Registry. When PowerShell launches, it reads the registry to get the env vars for the current session. However, it does not update the registry whenever you create or remove a env var using the env: provider. To manipulate env var in the registry for permanent use, use the .NET object like the following: View # displaying a env var named \u201cmyY\u201d of the category \u201cUser\u201d. [environment]::GetEnvironmentVariable(\"myY\", \"User\") The possible values for the second argument in GetEnvironmentVariable are: \"Process\", \"User\", \"Machine\". Create, Set # creates \u201cmyY\u201d of category \u201cUser\u201d, and set the value to \u201c\"la la\"\u201d [Environment]::SetEnvironmentVariable(\"myY\", \"la la\", \"User\")","title":"PS Snippets"},{"location":"Powershell/Snippets/#common-ps-snippets","text":"Common PS Snippets Select-String Convert between Secure Password and Plain Password Write-Debug, Write-Verbose, Write-Error and Out-String Create a C# function and populate PSObject in the function Use switch statement Use switch to check PsCmdlet.ParameterSet Use Invoke-RestMethod to get GitHubOAuth Token Use try catch and get the error using $Error[0] Detect 64bit or 32bit then add DLL Use slect (select-object) to add a new property Environment variables","title":"Common PS Snippets"},{"location":"Powershell/Snippets/#select-string","text":"Perform a case sensitive matching of literal strings: PS C:\\> \"Hello\",\"HELLO\" | select-string -pattern \"HELLO\" -casesensitive Search through all files with the .xml file extension in the current directory and display the lines in those files that include the case sensitive string \"Princess\": PS C:\\> select-string -path *.xml -pattern \"Princess\" -casesensitive Retrieve the last 100 events from the application event log and filter to show only those containing the message string \"failed\": PS C:\\> $events = get-eventlog -logname application -newest 100 PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" Now include 2 lines before and 3 lines after each matching line - line numbers will appear in the output with a > prefixing the matching line: PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" -Context 2,3 Examine all files in the subdirectories of C:\\Windows\\System32 with the .txt file name extension and search for the Case-Sensitive string \"Microsoft\": PS C:\\> get-childitem c:\\windows\\system32\\* -include *.txt -recurse | select-string -pattern \"Microsoft\" -casesensitive Select lines from a file containing \"Total Sales\" and then split the matching lines: PS C:\\> $demo = get-content C:\\demo\\sales.txt PS C:\\> $demo | select-string \"Total Sales\" | %{$_.line.split()}","title":"Select-String"},{"location":"Powershell/Snippets/#convert-between-secure-password-and-plain-password","text":"if ($Password) { $BSTR = [System.Runtime.InteropServices.Marshal]::SecureStringToBSTR($Password) $PlainPassword = [System.Runtime.InteropServices.Marshal]::PtrToStringAuto($BSTR) $ConnectionString += \"Password=$PlainPassword;\" }","title":"Convert between Secure Password and Plain Password"},{"location":"Powershell/Snippets/#write-debug-write-verbose-write-error-and-out-string","text":"Try { $conn.Open() } Catch { Write-Error $_ continue } Write-Debug \"ConnectionString $ConnectionString\" Write-Verbose \"Created SQLiteConnection:`n$($Conn | Out-String)\"","title":"Write-Debug, Write-Verbose, Write-Error and Out-String"},{"location":"Powershell/Snippets/#create-a-c-function-and-populate-psobject-in-the-function","text":"If($As -eq \"PSObject\") { #This code scrubs DBNulls. Props to Dave Wyatt $cSharp = @' using System; using System.Data; using System.Management.Automation; public class DBNullScrubber { public static PSObject DataRowToPSObject(DataRow row) { PSObject psObject = new PSObject(); if (row != null && (row.RowState & DataRowState.Detached) != DataRowState.Detached) { foreach (DataColumn column in row.Table.Columns) { Object value = null; if (!row.IsNull(column)) { value = row[column]; } psObject.Properties.Add(new PSNoteProperty(column.ColumnName, value)); } } return psObject; } } '@ Try { Add-Type -TypeDefinition $cSharp -ReferencedAssemblies 'System.Data','System.Xml' -ErrorAction stop } Catch { If(-not $_.ToString() -like \"*The type name 'DBNullScrubber' already exists*\") { Write-Warning \"Could not load DBNullScrubber. Defaulting to DataRow output: $_\" $As = \"Datarow\" } } } To use the new class and function foreach ($row in $ds.Tables[0].Rows) { [DBNullScrubber]::DataRowToPSObject($row) }","title":"Create a C# function and populate PSObject in the function"},{"location":"Powershell/Snippets/#use-switch-statement","text":"First block is a string or Default or a condition block switch ($ErrorActionPreference.tostring()) { {'SilentlyContinue','Ignore' -contains $_} {} 'Stop' { Throw $Err } 'Continue' { Write-Error $Err} Default { Write-Error $Err} }","title":"Use switch statement"},{"location":"Powershell/Snippets/#use-switch-to-check-pscmdletparameterset","text":"Note [string]::IsNullOrEmpty use throw \"Error message\" to throw an error For long lines, use ` to continue lines switch ($PsCmdlet.ParameterSetName) { 'repo' { $missingOwner = [string]::IsNullOrEmpty($Owner) $missingRepo = [string]::IsNullOrEmpty($Repository) if ($missingOwner -and $missingRepo) { $remotes = GetRemotes #first remote in order here wins! 'upstream', 'origin' | % { if ([string]::IsNullOrEmpty($Owner) -and $remotes.$_) { $Owner = $remotes.$_.owner $Repository = $remotes.$_.repository Write-Host \"Found $_ remote with owner $Owner\" } } ... ... throw \"An Owner and Repository must be specified together\" } # accept null or lower case if ($Milestone) { $Milestone = $Milestone.ToLower() } GetRepoIssues $Owner $Repository $Milestone $State.ToLower() ` $Assignee $Creator $Mentioned $Labels $Sort.ToLower() ` $Direction.ToLower() $PsBoundParameters.Since } 'user' { if ([string]::IsNullOrEmpty($Env:GITHUB_OAUTH_TOKEN)) { throw \"Set GITHUB_OAUTH_TOKEN env variable \"} GetUserIssues $Filter.ToLower() $State.ToLower() $Labels ` $Sort.ToLower() $Direction.ToLower() $PsBoundParameters.Since } }","title":"Use switch to check PsCmdlet.ParameterSet"},{"location":"Powershell/Snippets/#use-invoke-restmethod-to-get-githuboauth-token","text":"it's using basic auth, use GetBytes to convert string to bytes then use ToBase64String to convert them to base64 string function Get-GitHubOAuthTokens { [CmdletBinding()] param( [Parameter(Mandatory = $true)] [string] $UserName, [Parameter(Mandatory = $true)] [string] $Password ) try { $params = @{ Uri = 'https://api.github.com/authorizations'; Headers = @{ Authorization = 'Basic ' + [Convert]::ToBase64String( [Text.Encoding]::ASCII.GetBytes(\"$($userName):$($password)\")); } } $global:GITHUB_API_OUTPUT = Invoke-RestMethod @params #Write-Verbose $global:GITHUB_API_OUTPUT $global:GITHUB_API_OUTPUT | % { $date = [DateTime]::Parse($_.created_at).ToString('g') Write-Host \"`n$($_.app.name) - Created $date\" Write-Host \"`t$($_.token)`n`t$($_.app.url)\" } } catch { Write-Error \"An unexpected error occurred (bad user/password?) $($Error[0])\" } }","title":"Use Invoke-RestMethod to get GitHubOAuth Token"},{"location":"Powershell/Snippets/#use-try-catch-and-get-the-error-using-error0","text":"catch { Write-Error \"An unexpected error occurred $($Error[0])\" }","title":"Use try catch and get the error using $Error[0]"},{"location":"Powershell/Snippets/#detect-64bit-or-32bit-then-add-dll","text":"#Pick and import assemblies: if([IntPtr]::size -eq 8) #64 { $SQLiteAssembly = Join-path $PSScriptRoot \"x64\\System.Data.SQLite.dll\" } elseif([IntPtr]::size -eq 4) #32 { $SQLiteAssembly = Join-path $PSScriptRoot \"x86\\System.Data.SQLite.dll\" } else { Throw \"Something is odd with bitness...\" } if( -not ($Library = Add-Type -path $SQLiteAssembly -PassThru -ErrorAction stop) ) { Throw \"This module requires the ADO.NET driver for SQLite:`n`thttp://system.data.sqlite.org/index.html/doc/trunk/www/downloads.wiki\" }","title":"Detect 64bit or 32bit then add DLL"},{"location":"Powershell/Snippets/#use-slect-select-object-to-add-a-new-property","text":"get-process| select ProcessName, @{ Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} | select -First 4 ProcessName Start Day ----------- --------- AccelerometerSt Sunday AcroRd32 Monday AcroRd32 Monday Adobe CEF Helper Sunday Display only the name, ID and Working Set(WS) properties of Get-Process: PS C:\\> get-process | select-object ProcessName,Id,WS Display only the Name and modules properties of Get-Process, use -ExpandProperty to display the details contained within the modules property: PS C:\\> get-process | select-object ProcessName -expandproperty modules | format-list Display the 5 processes that are using the most memory (WS=Working Set): PS C:\\> get-process | sort-object -property WS | select-object -Last 5 Display the name and claculate the start day of the processes running: PS C:\\> get-process | select-object ProcessName,@{Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} Get the first (newest) and last (oldest) events in the Windows PowerShell event log: PS C:\\> $evts = get-eventlog -log \"Windows PowerShell\" PS C:\\> $evts | select-object -index 0, ($evts.count - 1) Retrieve all the names listed in the Servers.txt file, except for the first one: PS C:\\> get-content servers.txt | select-object -skip 1","title":"Use slect (select-object) to add a new property"},{"location":"Powershell/Snippets/#environment-variables","text":"powershell gci env: # list environment variables dir env: # or gci env: # show env vars whose name contains \u201cpath\u201d Get-ChildItem Env:*path* | format-list # show value of \u201cpath\u201d $env:path Set or Remove # sets a env var named myX for current session $env:myX = \"alice\" # get value of a env var $env:myX # deleting a env var from the current session Remove-Item env:myX # adding path to the path env var $env:path = $env:path + \";C:\\Program Files (x86)\\ErgoEmacs\\hunspell\" View/Set Permament Environment Variables Permanent env vars are stored in Windows Registry. When PowerShell launches, it reads the registry to get the env vars for the current session. However, it does not update the registry whenever you create or remove a env var using the env: provider. To manipulate env var in the registry for permanent use, use the .NET object like the following: View # displaying a env var named \u201cmyY\u201d of the category \u201cUser\u201d. [environment]::GetEnvironmentVariable(\"myY\", \"User\") The possible values for the second argument in GetEnvironmentVariable are: \"Process\", \"User\", \"Machine\". Create, Set # creates \u201cmyY\u201d of category \u201cUser\u201d, and set the value to \u201c\"la la\"\u201d [Environment]::SetEnvironmentVariable(\"myY\", \"la la\", \"User\")","title":"Environment variables"}]}