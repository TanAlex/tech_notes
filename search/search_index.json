{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tech Notes Tech Notes Run mkdocs to generate sites htmls Quote Run mkdocs to generate sites htmls mkdocs build mkdocs serve # publish to git pages mkdocs gh-deploy It will be published on https://tanalex.github.io/tech_notes/ Quote _________________________________________ / When the only tool you own is a hammer, \\ | every problem begins to resemble a | \\ nail. (Abraham Maslow) / ----------------------------------------- \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || ||","title":"Home"},{"location":"#tech-notes","text":"Tech Notes Run mkdocs to generate sites htmls Quote","title":"Tech Notes"},{"location":"#run-mkdocs-to-generate-sites-htmls","text":"mkdocs build mkdocs serve # publish to git pages mkdocs gh-deploy It will be published on https://tanalex.github.io/tech_notes/","title":"Run mkdocs to generate sites htmls"},{"location":"#quote","text":"_________________________________________ / When the only tool you own is a hammer, \\ | every problem begins to resemble a | \\ nail. (Abraham Maslow) / ----------------------------------------- \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || ||","title":"Quote"},{"location":"CSS/QuickNotes/","text":"CSS Quick Notes Reactive Container sit in the mid of the row @media (min-width: 1200px) .container { max-width: 1140px; } @media (min-width: 992px) .container { max-width: 960px; } @media (min-width: 768px) .container { max-width: 720px; } @media (min-width: 576px) .container { max-width: 540px; } .container { width: 100%; margin-right: auto; margin-left: auto; } Simple <a using .button class .button, button[type=submit], header+.section_wrapper .section_nav_wrapper ul li.free-trial a { padding: 0 20px; background-color: #63db2a; text-align: center; font-family: \"Open Sans\",Sans-Serif; color: #fff; display: inline-block; border-radius: 6px; font-size: 16px; line-height: 42px; transition: all .3s ease-in-out; min-width: 130px; height: 42px; } Align <img to center img { align-self: center; } .align-middle { vertical-align: middle!important; } img { max-width: 100%; height: auto; } Usage: <div class=\"col-12 col-md-6 d-flex justify-content-center\"> <img src=\"Band1.svg?ext=.svg\" alt=\"API Documentation\" class=\"align-middle\"> </div>","title":"CSS Quick Notes"},{"location":"CSS/QuickNotes/#css-quick-notes","text":"","title":"CSS Quick Notes"},{"location":"CSS/QuickNotes/#reactive-container-sit-in-the-mid-of-the-row","text":"@media (min-width: 1200px) .container { max-width: 1140px; } @media (min-width: 992px) .container { max-width: 960px; } @media (min-width: 768px) .container { max-width: 720px; } @media (min-width: 576px) .container { max-width: 540px; } .container { width: 100%; margin-right: auto; margin-left: auto; }","title":"Reactive Container sit in the mid of the row"},{"location":"CSS/QuickNotes/#simple-a-using-button-class","text":".button, button[type=submit], header+.section_wrapper .section_nav_wrapper ul li.free-trial a { padding: 0 20px; background-color: #63db2a; text-align: center; font-family: \"Open Sans\",Sans-Serif; color: #fff; display: inline-block; border-radius: 6px; font-size: 16px; line-height: 42px; transition: all .3s ease-in-out; min-width: 130px; height: 42px; }","title":"Simple &lt;a  using .button class"},{"location":"CSS/QuickNotes/#align-img-to-center","text":"img { align-self: center; } .align-middle { vertical-align: middle!important; } img { max-width: 100%; height: auto; } Usage: <div class=\"col-12 col-md-6 d-flex justify-content-center\"> <img src=\"Band1.svg?ext=.svg\" alt=\"API Documentation\" class=\"align-middle\"> </div>","title":"Align &lt;img to center"},{"location":"DockerSwarm/","text":"Docker Swarm Stack with Traefik solution Docker Swarm Stack with Traefik solution Architect diagram High level explanation Traefik service act as load-balancer Frontier service example Backtier service example Steps to deploy and test Architect diagram High level explanation Lets say you have 8 VM Nodes showing as the Gray Box in the diagram above You plan to build a few fronttier web applications One web UI app written in TS or JS listening on port 5001 One Web REST API app writtern in DotNet Core listening on port 5002 One web GraphQL API app writtern in Javascript listening on port 5003 You want to use the following URL to access these services Web UI app: http://yourdomain.com/www REST API app: http://yourdomain.com/api GraphQL API app: http://yourdomain.com/graphql Traefik instance here can help, it works just like a reverse proxy. So based on a frontend rule like \"traefik.frontend.rule=PathPrefixStrip:/www , it will allow the request to be redirected/forwared to the backend service for the Web UI app This will be the same for backtier applications. You might want to run a few backtier app too One backend OSS app listening on port 60001 One backend Billing app listening on port 60002 One backend media app listing on port 60003 You want to access them from the fronttier containers using URL like these: Backend OSS app: http://backtier/oss/v1 Backend Billing app: http://backtier/billing/v1 Backend Media app: http://backtier/media/v1 Backend Media app version 2: http://backtier/media/v2 Now we need a 2nd Traefik instance to handle these ones Both of these 2 Traefik instances will listen on port 80 and 443, but only the fronttier Traefik instance docker container exposed/mapped to Node port 80 and 443, the backtier mapped to different ports or simply no need to map to Node Ports All the frontend containers can use http://backtier to access the backtier Traefik service anyway. Because we allow any container to deploy on any hosts to provide maximum flexibility, we will use a trick to differentiate which contains should be managed by which Traefik instance The way to achieve that is to use a tag on the Traefik service like \"--constraints=tag==traefik-fronttier\" All the containers with a tag like traefik-tags=traefik-fronttier will be associated only to the \"fronttier\" Traefik instance The same type of config works for backtier apps as well. Traefik service act as load-balancer There are 2 Traefik instances to handle both fronttier and backtier services Note: \"--constraints=tag==traefik-fronttier\" controls only the containers with traefik-tags=traefik-fronttier tags will be controlled by the fronttier traefik controller \"--constraints=tag==traefik-backtier\" controls only the containers with traefik-tags=traefik-backtier tags will be controlled by the backtier traefik controller restart_policy set to condition: any will allow these 2 traefik container/service to auto restart after node reboot or docker daemon reboot. constraints: [node.role == manager] will force these 2 traefik services to run only on Swarm Manager role nodes version: '3.3' networks: frontend: driver: overlay attachable: true volumes: data: services: fronttier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-fronttier\" - \"--web\" ports: - \"80:80\" # The HTTP port - \"443:443\" - \"8000:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: #condition: on-failure condition: any backtier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-backtier\" - \"--web\" - \"--loglevel=DEBUG\" ports: - \"7180:80\" # The HTTP port - \"7443:443\" - \"7880:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: condition: any Frontier service example The following simulate a simple fronttier webapp Note: extra_hosts are the list of the hosts Docker will put them into the container's /etc/hosts file This sample lists external IP for the redis , mongodb and consul services. extra_hosts will allow apps in docker container to communicate to external services constraints: - node.role == worker set the service contains to run only in nodes whose role is a worker - \"traefik.basic.port=5000\" this is the port for our webapp:1.1 service. This webapp listens and exposes on port 5000 - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" this is Traefik setting for URL mapping. Any request to /webapp will be forwarded to port 5000 (the webapp service itself) \"traefik.backend=webapp\" set the name of the service Traefik will forward the request to, which is the service itself - \"traefik.docker.network=okto_frontend\" this is the Docker overlay network which Traefik and all services use to communicate - \"traefik.tags=traefik-fronttier\" is to set the webapp service to associate with the traefik-fronttier Traefik instance version: \"3.3\" services: webapp: image: devmr1oktodock1:5000/webapp:1.1 extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=5000\" - \"traefik.basic.protocol=http\" - \"traefik.backend=webapp\" - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-fronttier\" Backtier service example whoami: image: devmr1oktodock1:5000/whoami:latest extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=80\" - \"traefik.basic.protocol=http\" - \"traefik.backend=whoami\" - \"traefik.frontend.rule=PathPrefixStrip:/whoami\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-backtier\" networks: frontend: driver: overlay attachable: true Steps to deploy and test #Run this to deploy docker stack deploy -c docker-traefik-without-local-volumn.yml okto #Check if 2 instance's API interface (it was started using the --web flag in the yml) curl --noproxy '*' http://devmr1oktodock1:8000/api curl --noproxy '*' http://devmr1oktodock1:7880/api Once these 2 Traefik instances are running well, deploy both fronttier and backtier apps #Run this to deploy docker stack deploy -c docker-webapp.yml okto #Check the services curl --noproxy '*' http://devmr1oktodock1/webapp curl --noproxy '*' http://devmr1oktodock1:7180/whoami The following commands will scale the services to run multiple instances then check their status [root@devmr1oktodock1 multiple-traefik-stack]# docker service scale okto_webapp=3 okto_webapp scaled to 3 overall progress: 3 out of 3 tasks 1/3: running [==================================================>] 2/3: running [==================================================>] 3/3: running [==================================================>] verify: Service converged [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ldae6tup6v8s okto_webapp.1 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 37 minutes ago etexcwod5tux okto_webapp.2 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago klopqgsbw2pe okto_webapp.3 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_whoami ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ojzt1rgpxx4i okto_whoami.1 devmr1oktodock1:5000/whoami:latest devmr1oktodock2.br.devrep.tv.telus.net Running Running 10 minutes ago ji9aga2xq4e0 okto_whoami.2 devmr1oktodock1:5000/whoami:latest devmr1oktodock1.br.devrep.tv.telus.net Running Running 9 minutes ago jbnkom5oiv2a okto_whoami.3 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago ww7315qshpzd okto_whoami.4 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago","title":"DockerSwarm"},{"location":"DockerSwarm/#docker-swarm-stack-with-traefik-solution","text":"Docker Swarm Stack with Traefik solution Architect diagram High level explanation Traefik service act as load-balancer Frontier service example Backtier service example Steps to deploy and test","title":"Docker Swarm Stack with Traefik solution"},{"location":"DockerSwarm/#architect-diagram","text":"","title":"Architect diagram"},{"location":"DockerSwarm/#high-level-explanation","text":"Lets say you have 8 VM Nodes showing as the Gray Box in the diagram above You plan to build a few fronttier web applications One web UI app written in TS or JS listening on port 5001 One Web REST API app writtern in DotNet Core listening on port 5002 One web GraphQL API app writtern in Javascript listening on port 5003 You want to use the following URL to access these services Web UI app: http://yourdomain.com/www REST API app: http://yourdomain.com/api GraphQL API app: http://yourdomain.com/graphql Traefik instance here can help, it works just like a reverse proxy. So based on a frontend rule like \"traefik.frontend.rule=PathPrefixStrip:/www , it will allow the request to be redirected/forwared to the backend service for the Web UI app This will be the same for backtier applications. You might want to run a few backtier app too One backend OSS app listening on port 60001 One backend Billing app listening on port 60002 One backend media app listing on port 60003 You want to access them from the fronttier containers using URL like these: Backend OSS app: http://backtier/oss/v1 Backend Billing app: http://backtier/billing/v1 Backend Media app: http://backtier/media/v1 Backend Media app version 2: http://backtier/media/v2 Now we need a 2nd Traefik instance to handle these ones Both of these 2 Traefik instances will listen on port 80 and 443, but only the fronttier Traefik instance docker container exposed/mapped to Node port 80 and 443, the backtier mapped to different ports or simply no need to map to Node Ports All the frontend containers can use http://backtier to access the backtier Traefik service anyway. Because we allow any container to deploy on any hosts to provide maximum flexibility, we will use a trick to differentiate which contains should be managed by which Traefik instance The way to achieve that is to use a tag on the Traefik service like \"--constraints=tag==traefik-fronttier\" All the containers with a tag like traefik-tags=traefik-fronttier will be associated only to the \"fronttier\" Traefik instance The same type of config works for backtier apps as well.","title":"High level explanation"},{"location":"DockerSwarm/#traefik-service-act-as-load-balancer","text":"There are 2 Traefik instances to handle both fronttier and backtier services Note: \"--constraints=tag==traefik-fronttier\" controls only the containers with traefik-tags=traefik-fronttier tags will be controlled by the fronttier traefik controller \"--constraints=tag==traefik-backtier\" controls only the containers with traefik-tags=traefik-backtier tags will be controlled by the backtier traefik controller restart_policy set to condition: any will allow these 2 traefik container/service to auto restart after node reboot or docker daemon reboot. constraints: [node.role == manager] will force these 2 traefik services to run only on Swarm Manager role nodes version: '3.3' networks: frontend: driver: overlay attachable: true volumes: data: services: fronttier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-fronttier\" - \"--web\" ports: - \"80:80\" # The HTTP port - \"443:443\" - \"8000:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: #condition: on-failure condition: any backtier: image: devmr1oktodock1:5000/traefik:1.7 command: - \"--docker\" - \"--docker.swarmmode=true\" - \"--docker.domain=docker.localhost\" - \"--docker.watch=true\" - \"--docker.exposedbydefault=true\" - \"--docker.endpoint=unix:///var/run/docker.sock\" - \"--constraints=tag==traefik-backtier\" - \"--web\" - \"--loglevel=DEBUG\" ports: - \"7180:80\" # The HTTP port - \"7443:443\" - \"7880:8080\" # API volumes: - /var/run/docker.sock:/var/run/docker.sock # So that Traefik can listen to the Docker events networks: - frontend labels: - \"traefik.enable=false\" deploy: placement: constraints: [node.role == manager] restart_policy: condition: any","title":"Traefik service act as load-balancer"},{"location":"DockerSwarm/#frontier-service-example","text":"The following simulate a simple fronttier webapp Note: extra_hosts are the list of the hosts Docker will put them into the container's /etc/hosts file This sample lists external IP for the redis , mongodb and consul services. extra_hosts will allow apps in docker container to communicate to external services constraints: - node.role == worker set the service contains to run only in nodes whose role is a worker - \"traefik.basic.port=5000\" this is the port for our webapp:1.1 service. This webapp listens and exposes on port 5000 - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" this is Traefik setting for URL mapping. Any request to /webapp will be forwarded to port 5000 (the webapp service itself) \"traefik.backend=webapp\" set the name of the service Traefik will forward the request to, which is the service itself - \"traefik.docker.network=okto_frontend\" this is the Docker overlay network which Traefik and all services use to communicate - \"traefik.tags=traefik-fronttier\" is to set the webapp service to associate with the traefik-fronttier Traefik instance version: \"3.3\" services: webapp: image: devmr1oktodock1:5000/webapp:1.1 extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=5000\" - \"traefik.basic.protocol=http\" - \"traefik.backend=webapp\" - \"traefik.frontend.rule=PathPrefixStrip:/webapp\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-fronttier\"","title":"Frontier service example"},{"location":"DockerSwarm/#backtier-service-example","text":"whoami: image: devmr1oktodock1:5000/whoami:latest extra_hosts: - \"redis:172.25.83.76\" - \"mongodb:172.25.83.64\" - \"consul:172.25.83.61\" networks: - frontend deploy: placement: constraints: - node.role == worker restart_policy: condition: on-failure labels: - \"traefik.enable=true\" - \"traefik.basic.port=80\" - \"traefik.basic.protocol=http\" - \"traefik.backend=whoami\" - \"traefik.frontend.rule=PathPrefixStrip:/whoami\" - \"traefik.docker.network=okto_frontend\" - \"traefik.backend.loadbalancer.swarm=true\" - \"traefik.tags=traefik-backtier\" networks: frontend: driver: overlay attachable: true","title":"Backtier service example"},{"location":"DockerSwarm/#steps-to-deploy-and-test","text":"#Run this to deploy docker stack deploy -c docker-traefik-without-local-volumn.yml okto #Check if 2 instance's API interface (it was started using the --web flag in the yml) curl --noproxy '*' http://devmr1oktodock1:8000/api curl --noproxy '*' http://devmr1oktodock1:7880/api Once these 2 Traefik instances are running well, deploy both fronttier and backtier apps #Run this to deploy docker stack deploy -c docker-webapp.yml okto #Check the services curl --noproxy '*' http://devmr1oktodock1/webapp curl --noproxy '*' http://devmr1oktodock1:7180/whoami The following commands will scale the services to run multiple instances then check their status [root@devmr1oktodock1 multiple-traefik-stack]# docker service scale okto_webapp=3 okto_webapp scaled to 3 overall progress: 3 out of 3 tasks 1/3: running [==================================================>] 2/3: running [==================================================>] 3/3: running [==================================================>] verify: Service converged [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ldae6tup6v8s okto_webapp.1 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 37 minutes ago etexcwod5tux okto_webapp.2 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago klopqgsbw2pe okto_webapp.3 devmr1oktodock1:5000/webapp:1.1 devmr1oktodock3.br.devrep.tv.telus.net Running Running 14 seconds ago [root@devmr1oktodock1 multiple-traefik-stack]# docker service ps okto_whoami ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS ojzt1rgpxx4i okto_whoami.1 devmr1oktodock1:5000/whoami:latest devmr1oktodock2.br.devrep.tv.telus.net Running Running 10 minutes ago ji9aga2xq4e0 okto_whoami.2 devmr1oktodock1:5000/whoami:latest devmr1oktodock1.br.devrep.tv.telus.net Running Running 9 minutes ago jbnkom5oiv2a okto_whoami.3 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago ww7315qshpzd okto_whoami.4 devmr1oktodock1:5000/whoami:latest devmr1oktodock3.br.devrep.tv.telus.net Running Running 9 minutes ago","title":"Steps to deploy and test"},{"location":"Kubernetes/KubernetesNotes/","text":"Notes Notes Ingress Use Traefik for Ingress Create RBAC First create a new ServiceAccount to provide Traefik with the identity in your cluster. Next, let\u2019s create a ClusterRole with a set of permissions Finally, to enable these permissions, we should bind the ClusterRole to the Traefik ServiceAccount. Deploy Traefik to a Cluster Create service to use Traefik UI on port 8080 Create a Ingress service for Traefik Web UI Create NodePort just to allow access from node Setup Ingress service to do weight loadbalancing Ingress Reference Simple Ingress service This will route all traffic to the deaultbackend service apiVersion: extensions/v1beta1 kind: Ingress metadata: name: test-ingress spec: backend: serviceName: defaultbackend servicePort: 80 The following does a rewrite using annotation it also only redirect /microservice1 to the backend service called test apiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-example annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - http: paths: - path: /microservice1 backend: serviceName: test servicePort: 80 Use Traefik for Ingress Create RBAC First create a new ServiceAccount to provide Traefik with the identity in your cluster. apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress namespace: kube-system To create the ServiceAccount, save the manifest above in the traefik-service-acc.yaml and run: Run kubectl kubectl create -f traefik-service-acc.yaml serviceaccount \"traefik-ingress\" created Next, let\u2019s create a ClusterRole with a set of permissions which will be applied to the Traefik ServiceAccount. The ClusterRole will allow Traefik to manage and watch such resources as Services, Endpoints, Secrets, and Ingresses across all namespaces in your cluster. kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress rules: - apiGroups: - \"\" resources: - services - endpoints - secrets verbs: - get - list - watch - apiGroups: - extensions resources: - ingresses verbs: - get - list - watch Save this spec to the file traefik-cr.yaml and run: kubectl create -f traefik-cr.yaml clusterrole.rbac.authorization.k8s.io \u201ctraefik-ingress\u201d created Finally, to enable these permissions, we should bind the ClusterRole to the Traefik ServiceAccount. This can be done using the ClusterRoleBinding manifest: kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress subjects: - kind: ServiceAccount name: traefik-ingress namespace: kube-system Save this spec to the traefik-crb.yaml and run the following command: kubectl create -f traefik-crb.yaml clusterrolebinding.rbac.authorization.k8s.io \u201ctraefik-ingress\u201d created Deploy Traefik to a Cluster Deployment manifest: kind: Deployment apiVersion: extensions/v1beta1 metadata: name: traefik-ingress namespace: kube-system labels: k8s-app: traefik-ingress-lb spec: replicas: 1 selector: matchLabels: k8s-app: traefik-ingress-lb template: metadata: labels: k8s-app: traefik-ingress-lb name: traefik-ingress-lb spec: serviceAccountName: traefik-ingress terminationGracePeriodSeconds: 60 containers: - image: traefik name: traefik-ingress-lb ports: - name: http containerPort: 80 - name: admin containerPort: 8080 args: - --api - --kubernetes - --logLevel=INFO Save this manifest to the traefik-deployment.yaml file and create the Deployment running the following command: kubectl create -f traefik-deployment.yaml deployment.extensions \u201ctraefik-ingress\u201d created Now, let\u2019s check to see if the Traefik Pods were successfully created: kubectl --namespace=kube-system get pods NAME READY STATUS RESTARTS AGE .... storage-provisioner 1/1 Running 3 23d traefik-ingress-54d6d8d9cc-ls6cs 1/1 Running 0 1m Create service to use Traefik UI on port 8080 apiVersion: v1 kind: Service metadata: name: traefik-web-ui namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - name: web port: 80 targetPort: 8080 Save this manifest to traefik-webui-svc.yaml and run: kubectl create -f traefik-webui-svc.yaml service \u201ctraefik-web-ui\u201d created Let\u2019s verify that the Service was created: kubectl describe svc traefik-web-ui --namespace=kube-system Name: traefik-web-ui Namespace: kube-system Labels: <none> Annotations: <none> Selector: k8s-app=traefik-ingress-lb Type: ClusterIP IP: 10.98.230.58 Port: web 80/TCP TargetPort: 8080/TCP Endpoints: 172.17.0.6:8080 Session Affinity: None Events: <none> Create a Ingress service for Traefik Web UI We need to create an Ingress resource pointing to the Traefik Web UI backend. that only direct traffic when the host is traefik-ui.minikube apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-web-ui namespace: kube-system spec: rules: - host: traefik-ui.minikube http: paths: - path: / backend: serviceName: traefik-web-ui servicePort: web In essence, this Ingress routes all requests to traefik-ui.minikube host to the Traefik Web UI exposed by the Service created in the step above. Save the spec to the traefik-ingress.yaml and run: kubectl create -f traefik-ingress.yaml ingress.extensions \u201ctraefik-web-ui\u201d created Create NodePort just to allow access from node kind: Service apiVersion: v1 metadata: name: traefik-ingress-service namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - protocol: TCP port: 80 name: web - protocol: TCP port: 8080 name: admin type: NodePort Save this manifest to traefik-svc.yaml and create the Service: kubectl create -f traefik-svc.yaml service \u201ctraefik-ingress-service\u201d created Check the NodePort kubectl describe svc traefik-ingress-service --namespace=kube-system Name: traefik-ingress-service Namespace: kube-system Labels: <none> Annotations: <none> Selector: k8s-app=traefik-ingress-lb Type: NodePort IP: 10.102.215.64 Port: web 80/TCP TargetPort: 80/TCP NodePort: web 30565/TCP Endpoints: 172.17.0.6:80 Port: admin 8080/TCP TargetPort: 8080/TCP NodePort: admin 30729/TCP Endpoints: 172.17.0.6:8080 Session Affinity: None External Traffic Policy: Cluster Events: <none> You can then access the endpoint using http://traefik-ui.minikube/<NodePort> In this case, NodePort is 30729 Setup Ingress service to do weight loadbalancing apiVersion: extensions/v1beta1 kind: Ingress metadata: annotations: traefik.ingress.kubernetes.io/service-weights: | animals-app: 99% animals-app-canary: 1% name: animals-app spec: rules: - http: paths: - backend: serviceName: animals-app servicePort: 80 path: / - backend: serviceName: animals-app-canary servicePort: 80 path: /","title":"Kubernetes"},{"location":"Kubernetes/KubernetesNotes/#notes","text":"Notes Ingress Use Traefik for Ingress Create RBAC First create a new ServiceAccount to provide Traefik with the identity in your cluster. Next, let\u2019s create a ClusterRole with a set of permissions Finally, to enable these permissions, we should bind the ClusterRole to the Traefik ServiceAccount. Deploy Traefik to a Cluster Create service to use Traefik UI on port 8080 Create a Ingress service for Traefik Web UI Create NodePort just to allow access from node Setup Ingress service to do weight loadbalancing","title":"Notes"},{"location":"Kubernetes/KubernetesNotes/#ingress","text":"Reference Simple Ingress service This will route all traffic to the deaultbackend service apiVersion: extensions/v1beta1 kind: Ingress metadata: name: test-ingress spec: backend: serviceName: defaultbackend servicePort: 80 The following does a rewrite using annotation it also only redirect /microservice1 to the backend service called test apiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-example annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - http: paths: - path: /microservice1 backend: serviceName: test servicePort: 80","title":"Ingress"},{"location":"Kubernetes/KubernetesNotes/#use-traefik-for-ingress","text":"","title":"Use Traefik for Ingress"},{"location":"Kubernetes/KubernetesNotes/#create-rbac","text":"","title":"Create RBAC"},{"location":"Kubernetes/KubernetesNotes/#first-create-a-new-serviceaccount-to-provide-traefik-with-the-identity-in-your-cluster","text":"apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress namespace: kube-system To create the ServiceAccount, save the manifest above in the traefik-service-acc.yaml and run: Run kubectl kubectl create -f traefik-service-acc.yaml serviceaccount \"traefik-ingress\" created","title":"First create a new ServiceAccount to provide Traefik with the identity in your cluster."},{"location":"Kubernetes/KubernetesNotes/#next-lets-create-a-clusterrole-with-a-set-of-permissions","text":"which will be applied to the Traefik ServiceAccount. The ClusterRole will allow Traefik to manage and watch such resources as Services, Endpoints, Secrets, and Ingresses across all namespaces in your cluster. kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress rules: - apiGroups: - \"\" resources: - services - endpoints - secrets verbs: - get - list - watch - apiGroups: - extensions resources: - ingresses verbs: - get - list - watch Save this spec to the file traefik-cr.yaml and run: kubectl create -f traefik-cr.yaml clusterrole.rbac.authorization.k8s.io \u201ctraefik-ingress\u201d created","title":"Next, let\u2019s create a ClusterRole with a set of permissions"},{"location":"Kubernetes/KubernetesNotes/#finally-to-enable-these-permissions-we-should-bind-the-clusterrole-to-the-traefik-serviceaccount","text":"This can be done using the ClusterRoleBinding manifest: kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress subjects: - kind: ServiceAccount name: traefik-ingress namespace: kube-system Save this spec to the traefik-crb.yaml and run the following command: kubectl create -f traefik-crb.yaml clusterrolebinding.rbac.authorization.k8s.io \u201ctraefik-ingress\u201d created","title":"Finally, to enable these permissions, we should bind the ClusterRole to the Traefik ServiceAccount."},{"location":"Kubernetes/KubernetesNotes/#deploy-traefik-to-a-cluster","text":"Deployment manifest: kind: Deployment apiVersion: extensions/v1beta1 metadata: name: traefik-ingress namespace: kube-system labels: k8s-app: traefik-ingress-lb spec: replicas: 1 selector: matchLabels: k8s-app: traefik-ingress-lb template: metadata: labels: k8s-app: traefik-ingress-lb name: traefik-ingress-lb spec: serviceAccountName: traefik-ingress terminationGracePeriodSeconds: 60 containers: - image: traefik name: traefik-ingress-lb ports: - name: http containerPort: 80 - name: admin containerPort: 8080 args: - --api - --kubernetes - --logLevel=INFO Save this manifest to the traefik-deployment.yaml file and create the Deployment running the following command: kubectl create -f traefik-deployment.yaml deployment.extensions \u201ctraefik-ingress\u201d created Now, let\u2019s check to see if the Traefik Pods were successfully created: kubectl --namespace=kube-system get pods NAME READY STATUS RESTARTS AGE .... storage-provisioner 1/1 Running 3 23d traefik-ingress-54d6d8d9cc-ls6cs 1/1 Running 0 1m","title":"Deploy Traefik to a Cluster"},{"location":"Kubernetes/KubernetesNotes/#create-service-to-use-traefik-ui-on-port-8080","text":"apiVersion: v1 kind: Service metadata: name: traefik-web-ui namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - name: web port: 80 targetPort: 8080 Save this manifest to traefik-webui-svc.yaml and run: kubectl create -f traefik-webui-svc.yaml service \u201ctraefik-web-ui\u201d created Let\u2019s verify that the Service was created: kubectl describe svc traefik-web-ui --namespace=kube-system Name: traefik-web-ui Namespace: kube-system Labels: <none> Annotations: <none> Selector: k8s-app=traefik-ingress-lb Type: ClusterIP IP: 10.98.230.58 Port: web 80/TCP TargetPort: 8080/TCP Endpoints: 172.17.0.6:8080 Session Affinity: None Events: <none>","title":"Create service to use Traefik UI on port 8080"},{"location":"Kubernetes/KubernetesNotes/#create-a-ingress-service-for-traefik-web-ui","text":"We need to create an Ingress resource pointing to the Traefik Web UI backend. that only direct traffic when the host is traefik-ui.minikube apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-web-ui namespace: kube-system spec: rules: - host: traefik-ui.minikube http: paths: - path: / backend: serviceName: traefik-web-ui servicePort: web In essence, this Ingress routes all requests to traefik-ui.minikube host to the Traefik Web UI exposed by the Service created in the step above. Save the spec to the traefik-ingress.yaml and run: kubectl create -f traefik-ingress.yaml ingress.extensions \u201ctraefik-web-ui\u201d created","title":"Create a Ingress service for Traefik Web UI"},{"location":"Kubernetes/KubernetesNotes/#create-nodeport-just-to-allow-access-from-node","text":"kind: Service apiVersion: v1 metadata: name: traefik-ingress-service namespace: kube-system spec: selector: k8s-app: traefik-ingress-lb ports: - protocol: TCP port: 80 name: web - protocol: TCP port: 8080 name: admin type: NodePort Save this manifest to traefik-svc.yaml and create the Service: kubectl create -f traefik-svc.yaml service \u201ctraefik-ingress-service\u201d created Check the NodePort kubectl describe svc traefik-ingress-service --namespace=kube-system Name: traefik-ingress-service Namespace: kube-system Labels: <none> Annotations: <none> Selector: k8s-app=traefik-ingress-lb Type: NodePort IP: 10.102.215.64 Port: web 80/TCP TargetPort: 80/TCP NodePort: web 30565/TCP Endpoints: 172.17.0.6:80 Port: admin 8080/TCP TargetPort: 8080/TCP NodePort: admin 30729/TCP Endpoints: 172.17.0.6:8080 Session Affinity: None External Traffic Policy: Cluster Events: <none> You can then access the endpoint using http://traefik-ui.minikube/<NodePort> In this case, NodePort is 30729","title":"Create NodePort just to allow access from node"},{"location":"Kubernetes/KubernetesNotes/#setup-ingress-service-to-do-weight-loadbalancing","text":"apiVersion: extensions/v1beta1 kind: Ingress metadata: annotations: traefik.ingress.kubernetes.io/service-weights: | animals-app: 99% animals-app-canary: 1% name: animals-app spec: rules: - http: paths: - backend: serviceName: animals-app servicePort: 80 path: / - backend: serviceName: animals-app-canary servicePort: 80 path: /","title":"Setup Ingress service to do weight loadbalancing"},{"location":"Kubernetes/RollingUpdate/","text":"Rolling Update A sample deployment apiVersion: apps/v1 kind: Deployment metadata: labels: app: myapp name: myapp spec: replicas: 3 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - image: polarsquad/hello-world-app:master name: hello-world ports: - containerPort: 3000 Rolling update spec spec: strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 0 maxSurge: 1 Deploy cmd and status checking kubectl apply -f deployment.yaml $ kubectl rollout status deployment myapp Waiting for deployment \"myapp\" rollout to finish: 0 of 3 updated replicas are available\u2026 Waiting for deployment \"myapp\" rollout to finish: 1 of 3 updated replicas are available\u2026 Waiting for deployment \"myapp\" rollout to finish: 2 of 3 updated replicas are available\u2026 deployment \"myapp\" successfully rolled out Add status prob checking in YAML Kubernetes uses readiness probes to examine how the application is doing readinessProbe: httpGet: path: / port: 3000 Check status $ kubectl rollout status deployment myapp Waiting for deployment \"myapp\" rollout to finish: 1 out of 3 new replicas have been updated\u2026 error: deployment \"myapp\" exceeded its progress deadline Use progress deadline seconds to specify how long to wait for the deployment process Reference Progress Deadline Seconds .spec.progressDeadlineSeconds is an optional field that specifies the number of seconds you want to wait for your Deployment to progress before the system reports back that the Deployment has failed progressing - surfaced as a condition with Type=Progressing, Status=False. and Reason=ProgressDeadlineExceeded in the status of the resource. The deployment controller will keep retrying the Deployment. In the future, once automatic rollback will be implemented, the deployment controller will roll back a Deployment as soon as it observes such a condition Simple Shell script to automate deployment kubectl apply -f myapp.yaml if ! kubectl rollout status deployment myapp; then kubectl rollout undo deployment myapp kubectl rollout status deployment myapp exit 1 fi","title":"Rolling Update"},{"location":"Kubernetes/RollingUpdate/#rolling-update","text":"","title":"Rolling Update"},{"location":"Kubernetes/RollingUpdate/#a-sample-deployment","text":"apiVersion: apps/v1 kind: Deployment metadata: labels: app: myapp name: myapp spec: replicas: 3 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - image: polarsquad/hello-world-app:master name: hello-world ports: - containerPort: 3000","title":"A sample deployment"},{"location":"Kubernetes/RollingUpdate/#rolling-update-spec","text":"spec: strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 0 maxSurge: 1","title":"Rolling update spec"},{"location":"Kubernetes/RollingUpdate/#deploy-cmd-and-status-checking","text":"kubectl apply -f deployment.yaml $ kubectl rollout status deployment myapp Waiting for deployment \"myapp\" rollout to finish: 0 of 3 updated replicas are available\u2026 Waiting for deployment \"myapp\" rollout to finish: 1 of 3 updated replicas are available\u2026 Waiting for deployment \"myapp\" rollout to finish: 2 of 3 updated replicas are available\u2026 deployment \"myapp\" successfully rolled out","title":"Deploy cmd and status checking"},{"location":"Kubernetes/RollingUpdate/#add-status-prob-checking-in-yaml","text":"Kubernetes uses readiness probes to examine how the application is doing readinessProbe: httpGet: path: / port: 3000 Check status $ kubectl rollout status deployment myapp Waiting for deployment \"myapp\" rollout to finish: 1 out of 3 new replicas have been updated\u2026 error: deployment \"myapp\" exceeded its progress deadline Use progress deadline seconds to specify how long to wait for the deployment process Reference Progress Deadline Seconds .spec.progressDeadlineSeconds is an optional field that specifies the number of seconds you want to wait for your Deployment to progress before the system reports back that the Deployment has failed progressing - surfaced as a condition with Type=Progressing, Status=False. and Reason=ProgressDeadlineExceeded in the status of the resource. The deployment controller will keep retrying the Deployment. In the future, once automatic rollback will be implemented, the deployment controller will roll back a Deployment as soon as it observes such a condition","title":"Add status prob checking in YAML"},{"location":"Kubernetes/RollingUpdate/#simple-shell-script-to-automate-deployment","text":"kubectl apply -f myapp.yaml if ! kubectl rollout status deployment myapp; then kubectl rollout undo deployment myapp kubectl rollout status deployment myapp exit 1 fi","title":"Simple Shell script to automate deployment"},{"location":"Powershell/","text":"Powershell Note Powershell Note Quick note Path of running script Get full path from absolute or relative path Awsome Powershell and other useful sites Quick note Write-Debug won't print out anything unless you set $DebugPreference = \"Continue\" That will cause all Write-Debug to print To set it back to defualt $DebugPreference = SilentlyContinue Will stop printing Write-Debug again Path of running script PowerShell 3+ The path of a running scripts is: $PSCommandPath Its directory is: $PSScriptRoot PowerShell 2 The path of a running scripts is: $MyInvocation.MyCommand.Path Its directory is: $PSScriptRoot = Split-Path $MyInvocation.MyCommand.Path -Parent Get full path from absolute or relative path resolve-path \"c:\\temp\\.\\PIPELINE\\..\\PIPELINE\\Configs\" Path ---- C:\\temp\\PIPELINE\\Configs PS C:\\temp\\PIPELINE> resolve-path \"Configs\" Path ---- C:\\temp\\PIPELINE\\Configs Awsome Powershell and other useful sites Awsome Powershell PlatyPS generate module help in Markdown","title":"Powershell Note"},{"location":"Powershell/#powershell-note","text":"Powershell Note Quick note Path of running script Get full path from absolute or relative path Awsome Powershell and other useful sites","title":"Powershell Note"},{"location":"Powershell/#quick-note","text":"Write-Debug won't print out anything unless you set $DebugPreference = \"Continue\" That will cause all Write-Debug to print To set it back to defualt $DebugPreference = SilentlyContinue Will stop printing Write-Debug again","title":"Quick note"},{"location":"Powershell/#path-of-running-script","text":"PowerShell 3+ The path of a running scripts is: $PSCommandPath Its directory is: $PSScriptRoot PowerShell 2 The path of a running scripts is: $MyInvocation.MyCommand.Path Its directory is: $PSScriptRoot = Split-Path $MyInvocation.MyCommand.Path -Parent","title":"Path of running script"},{"location":"Powershell/#get-full-path-from-absolute-or-relative-path","text":"resolve-path \"c:\\temp\\.\\PIPELINE\\..\\PIPELINE\\Configs\" Path ---- C:\\temp\\PIPELINE\\Configs PS C:\\temp\\PIPELINE> resolve-path \"Configs\" Path ---- C:\\temp\\PIPELINE\\Configs","title":"Get full path from absolute or relative path"},{"location":"Powershell/#awsome-powershell-and-other-useful-sites","text":"Awsome Powershell PlatyPS generate module help in Markdown","title":"Awsome Powershell and other useful sites"},{"location":"Powershell/Functions/","text":"Powershell functions notes Powershell functions notes ParameterSet and CmdletBinding Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments Function help doc string ParameterSet and CmdletBinding Notable points: Reference DefaultParameterSetName [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] Use [string[]] to indicate it's a string array @() [ValidatePattern('^*$|^none$|^.+$')] [ValidateSet('open', 'closed')] [AllowNull()] [ValidateNotNull()] [ValidateRange(0,10)] [ValidateRange(\"Positive\")] [ValidateScript({$_ -ge (Get-Date)})] [DateTime]$EventDate function Get-GitHubIssues { [CmdletBinding(DefaultParameterSetName='repo')] param( [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] [string] $Owner = $null, [Parameter(Mandatory = $false, Position=1, ParameterSetName='repo')] [string] $Repository = $null, [Parameter(Mandatory = $false, ParameterSetName='user')] [switch] $ForUser, [Parameter(Mandatory = $false)] [ValidateSet('open', 'closed')] $State = 'open', [Parameter(Mandatory = $false, ParameterSetName='user')] [ValidateSet('assigned', 'created', 'mentioned', 'subscribed')] $Filter = 'assigned', [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^\\d+$')] $Milestone, [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^.+$')] $Assignee, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Creator, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Mentioned, [Parameter(Mandatory = $false)] [string[]] $Labels = @(), [Parameter(Mandatory = $false)] [ValidateSet('created', 'updated', 'comments')] $Sort = 'created', [Parameter(Mandatory = $false)] [ValidateSet('asc', 'desc')] $Direction = 'desc', [Parameter(Mandatory = $false)] [DateTime] [AllowNull()] #Optional string of a timestamp in ISO 8601 format: YYYY-MM-DDTHH:MM:SSZ $Since ) Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments Note [Alias( 'Instance', 'Instances', 'ServerInstance')] [ValidateNotNullOrEmpty()] [Switch] [OutputType([System.Data.SQLite.SQLiteConnection])] [cmdletbinding()] [OutputType([System.Data.SQLite.SQLiteConnection])] param( [Parameter( Position=0, Mandatory=$true, ValueFromPipeline=$true, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false, HelpMessage='SQL Server Instance required...' )] [Alias( 'Instance', 'Instances', 'ServerInstance', 'Server', 'Servers','cn','Path','File','FullName','Database' )] [ValidateNotNullOrEmpty()] [string[]] $DataSource, [Parameter( Position=2, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [System.Security.SecureString] $Password, [Parameter( Position=3, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [Switch] $ReadOnly, [Parameter( Position=4, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [bool] $Open = $True ) Function help doc string function Out-DataTable { <# .SYNOPSIS Creates a DataTable for an object .DESCRIPTION Creates a DataTable based on an object's properties. .PARAMETER InputObject One or more objects to convert into a DataTable .PARAMETER NonNullable A list of columns to set disable AllowDBNull on .INPUTS Object Any object can be piped to Out-DataTable .OUTPUTS System.Data.DataTable .EXAMPLE $dt = Get-psdrive | Out-DataTable # This example creates a DataTable from the properties of Get-psdrive and assigns output to $dt variable .EXAMPLE Get-Process | Select Name, CPU | Out-DataTable | Invoke-SQLBulkCopy -ServerInstance $SQLInstance -Database $Database -Table $SQLTable -force -verbose # Get a list of processes and their CPU, create a datatable, bulk import that data .NOTES Adapted from script by Marc van Orsouw and function from Chad Miller Version History v1.0 - Chad Miller - Initial Release v1.1 - Chad Miller - Fixed Issue with Properties v1.2 - Chad Miller - Added setting column datatype by property as suggested by emp0 v1.3 - Chad Miller - Corrected issue with setting datatype on empty properties v1.4 - Chad Miller - Corrected issue with DBNull v1.5 - Chad Miller - Updated example v1.6 - Chad Miller - Added column datatype logic with default to string v1.7 - Chad Miller - Fixed issue with IsArray v1.8 - ramblingcookiemonster - Removed if($Value) logic. This would not catch empty strings, zero, $false and other non-null items - Added perhaps pointless error handling .LINK https://github.com/RamblingCookieMonster/PowerShell .LINK Invoke-SQLBulkCopy .LINK Invoke-Sqlcmd2 .LINK New-SQLConnection .FUNCTIONALITY SQL #>","title":"PS Functions Note"},{"location":"Powershell/Functions/#powershell-functions-notes","text":"Powershell functions notes ParameterSet and CmdletBinding Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments Function help doc string","title":"Powershell functions notes"},{"location":"Powershell/Functions/#parameterset-and-cmdletbinding","text":"Notable points: Reference DefaultParameterSetName [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] Use [string[]] to indicate it's a string array @() [ValidatePattern('^*$|^none$|^.+$')] [ValidateSet('open', 'closed')] [AllowNull()] [ValidateNotNull()] [ValidateRange(0,10)] [ValidateRange(\"Positive\")] [ValidateScript({$_ -ge (Get-Date)})] [DateTime]$EventDate function Get-GitHubIssues { [CmdletBinding(DefaultParameterSetName='repo')] param( [Parameter(Mandatory = $false, Position=0, ParameterSetName='repo')] [string] $Owner = $null, [Parameter(Mandatory = $false, Position=1, ParameterSetName='repo')] [string] $Repository = $null, [Parameter(Mandatory = $false, ParameterSetName='user')] [switch] $ForUser, [Parameter(Mandatory = $false)] [ValidateSet('open', 'closed')] $State = 'open', [Parameter(Mandatory = $false, ParameterSetName='user')] [ValidateSet('assigned', 'created', 'mentioned', 'subscribed')] $Filter = 'assigned', [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^\\d+$')] $Milestone, [Parameter(Mandatory = $false, ParameterSetName='repo')] [ValidatePattern('^\\*$|^none$|^.+$')] $Assignee, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Creator, [Parameter(Mandatory = $false, ParameterSetName='repo')] [string] $Mentioned, [Parameter(Mandatory = $false)] [string[]] $Labels = @(), [Parameter(Mandatory = $false)] [ValidateSet('created', 'updated', 'comments')] $Sort = 'created', [Parameter(Mandatory = $false)] [ValidateSet('asc', 'desc')] $Direction = 'desc', [Parameter(Mandatory = $false)] [DateTime] [AllowNull()] #Optional string of a timestamp in ISO 8601 format: YYYY-MM-DDTHH:MM:SSZ $Since )","title":"ParameterSet and CmdletBinding"},{"location":"Powershell/Functions/#use-helpmessage-alias-valuefrompipelinebypropertyname-valuefromremainingarguments","text":"Note [Alias( 'Instance', 'Instances', 'ServerInstance')] [ValidateNotNullOrEmpty()] [Switch] [OutputType([System.Data.SQLite.SQLiteConnection])] [cmdletbinding()] [OutputType([System.Data.SQLite.SQLiteConnection])] param( [Parameter( Position=0, Mandatory=$true, ValueFromPipeline=$true, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false, HelpMessage='SQL Server Instance required...' )] [Alias( 'Instance', 'Instances', 'ServerInstance', 'Server', 'Servers','cn','Path','File','FullName','Database' )] [ValidateNotNullOrEmpty()] [string[]] $DataSource, [Parameter( Position=2, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [System.Security.SecureString] $Password, [Parameter( Position=3, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [Switch] $ReadOnly, [Parameter( Position=4, Mandatory=$false, ValueFromPipelineByPropertyName=$true, ValueFromRemainingArguments=$false )] [bool] $Open = $True )","title":"Use HelpMessage, Alias, ValueFromPipelineByPropertyName, ValueFromRemainingArguments"},{"location":"Powershell/Functions/#function-help-doc-string","text":"function Out-DataTable { <# .SYNOPSIS Creates a DataTable for an object .DESCRIPTION Creates a DataTable based on an object's properties. .PARAMETER InputObject One or more objects to convert into a DataTable .PARAMETER NonNullable A list of columns to set disable AllowDBNull on .INPUTS Object Any object can be piped to Out-DataTable .OUTPUTS System.Data.DataTable .EXAMPLE $dt = Get-psdrive | Out-DataTable # This example creates a DataTable from the properties of Get-psdrive and assigns output to $dt variable .EXAMPLE Get-Process | Select Name, CPU | Out-DataTable | Invoke-SQLBulkCopy -ServerInstance $SQLInstance -Database $Database -Table $SQLTable -force -verbose # Get a list of processes and their CPU, create a datatable, bulk import that data .NOTES Adapted from script by Marc van Orsouw and function from Chad Miller Version History v1.0 - Chad Miller - Initial Release v1.1 - Chad Miller - Fixed Issue with Properties v1.2 - Chad Miller - Added setting column datatype by property as suggested by emp0 v1.3 - Chad Miller - Corrected issue with setting datatype on empty properties v1.4 - Chad Miller - Corrected issue with DBNull v1.5 - Chad Miller - Updated example v1.6 - Chad Miller - Added column datatype logic with default to string v1.7 - Chad Miller - Fixed issue with IsArray v1.8 - ramblingcookiemonster - Removed if($Value) logic. This would not catch empty strings, zero, $false and other non-null items - Added perhaps pointless error handling .LINK https://github.com/RamblingCookieMonster/PowerShell .LINK Invoke-SQLBulkCopy .LINK Invoke-Sqlcmd2 .LINK New-SQLConnection .FUNCTIONALITY SQL #>","title":"Function help doc string"},{"location":"Powershell/Module/","text":"PS Modules Load module using ArgumentList You can use the \u2013ArgumentList parameter of the import-module cmdlet to pass arguments when loading a module. You should use a param block in your module to define your parameters: param( [parameter(Position=0,Mandatory=$false)][boolean]$BeQuiet=$true, [parameter(Position=1,Mandatory=$false)][string]$URL ) Then call the import-module cmdlet like this: import-module .\\myModule.psm1 -ArgumentList $True,'http://www.microsoft.com' As may have already noticed, you can only supply values (no names) to \u2013ArgumentList. So you should define you parameters carefully with the position argument. Use Set-Alias to link function in module to a script Typically, functions are in the psm1 file but you can write in regular script files then use Set-Alias to link them in the psm1 module file Set-Alias -Name Build-Checkpoint -Value (Join-Path $PSScriptRoot Build-Checkpoint.ps1) Set-Alias -Name Build-Parallel -Value (Join-Path $PSScriptRoot Build-Parallel.ps1) Set-Alias -Name Invoke-Build -Value (Join-Path $PSScriptRoot Invoke-Build.ps1) Export-ModuleMember -Alias Build-Checkpoint, Build-Parallel, Invoke-Build Import all function scripts in a folder This snipet is from PSSlack.psm1 #Get public and private function definition files. $Public = @( Get-ChildItem -Path $PSScriptRoot\\Public\\*.ps1 -ErrorAction SilentlyContinue ) $Private = @( Get-ChildItem -Path $PSScriptRoot\\Private\\*.ps1 -ErrorAction SilentlyContinue ) $ModuleRoot = $PSScriptRoot #Dot source the files Foreach($import in @($Public + $Private)) { Try { . $import.fullname } Catch { Write-Error -Message \"Failed to import function $($import.fullname): $_\" } } Beginning in PowerShell 3.0, there is a new automatic variable available called $PSScriptRoot. This variable previously was only available within modules. It always points to the folder the current script is located in (so it only starts to be useful once you actually save a script before you run it). You can use $PSScriptRoot to load additional resources relative to your script location. For example, if you decide to place some functions in a separate \"library\" script that is located in the same folder, this would load the library script and import all of its functions The following snipet handles PS v2 situation #handle PS2 if(-not $PSScriptRoot) { $PSScriptRoot = Split-Path $MyInvocation.MyCommand.Path -Parent } Export functions # $Public is an array imported above Export-ModuleMember -Function $Public.Basename -Variable _PSSlackColorMap Export using wild-cards Export-ModuleMember -Function 'Get-*' Powershell will auto convert array to string with comma Export-ModuleMember -Function @($Public + $Private)) Export-ModuleMember -Function New-GitHubOAuthToken, New-GitHubPullRequest, Get-GitHubIssues, Get-GitHubEvents, Get-GitHubRepositories, ... ... Check if the script is called by Dot Source or by Module (psm1) # if it's not dot sourced, call the function # Note: $args is an array, in order to pass them to function # need to convert that array to a space separated string if ( $MyInvocation.InvocationName -ne '.' -AND $MyInvocation.Line -ne '' ){ $new_args = $args[1..$($args.Length-1)] -join \" \" Invoke-Expression \"Okto-Login $new_args\" } #Check if it's called by psm1 module if ($MyInvocation.MyCommand.Name.EndsWith('.psm1')){ Export-ModuleMember -Function \"Set-Okto-Login\" }","title":"PS Modules Note"},{"location":"Powershell/Module/#ps-modules","text":"","title":"PS Modules"},{"location":"Powershell/Module/#load-module-using-argumentlist","text":"You can use the \u2013ArgumentList parameter of the import-module cmdlet to pass arguments when loading a module. You should use a param block in your module to define your parameters: param( [parameter(Position=0,Mandatory=$false)][boolean]$BeQuiet=$true, [parameter(Position=1,Mandatory=$false)][string]$URL ) Then call the import-module cmdlet like this: import-module .\\myModule.psm1 -ArgumentList $True,'http://www.microsoft.com' As may have already noticed, you can only supply values (no names) to \u2013ArgumentList. So you should define you parameters carefully with the position argument.","title":"Load module using ArgumentList"},{"location":"Powershell/Module/#use-set-alias-to-link-function-in-module-to-a-script","text":"Typically, functions are in the psm1 file but you can write in regular script files then use Set-Alias to link them in the psm1 module file Set-Alias -Name Build-Checkpoint -Value (Join-Path $PSScriptRoot Build-Checkpoint.ps1) Set-Alias -Name Build-Parallel -Value (Join-Path $PSScriptRoot Build-Parallel.ps1) Set-Alias -Name Invoke-Build -Value (Join-Path $PSScriptRoot Invoke-Build.ps1) Export-ModuleMember -Alias Build-Checkpoint, Build-Parallel, Invoke-Build","title":"Use Set-Alias to link function in module to a script"},{"location":"Powershell/Module/#import-all-function-scripts-in-a-folder","text":"This snipet is from PSSlack.psm1 #Get public and private function definition files. $Public = @( Get-ChildItem -Path $PSScriptRoot\\Public\\*.ps1 -ErrorAction SilentlyContinue ) $Private = @( Get-ChildItem -Path $PSScriptRoot\\Private\\*.ps1 -ErrorAction SilentlyContinue ) $ModuleRoot = $PSScriptRoot #Dot source the files Foreach($import in @($Public + $Private)) { Try { . $import.fullname } Catch { Write-Error -Message \"Failed to import function $($import.fullname): $_\" } } Beginning in PowerShell 3.0, there is a new automatic variable available called $PSScriptRoot. This variable previously was only available within modules. It always points to the folder the current script is located in (so it only starts to be useful once you actually save a script before you run it). You can use $PSScriptRoot to load additional resources relative to your script location. For example, if you decide to place some functions in a separate \"library\" script that is located in the same folder, this would load the library script and import all of its functions The following snipet handles PS v2 situation #handle PS2 if(-not $PSScriptRoot) { $PSScriptRoot = Split-Path $MyInvocation.MyCommand.Path -Parent }","title":"Import all function scripts in a folder"},{"location":"Powershell/Module/#export-functions","text":"# $Public is an array imported above Export-ModuleMember -Function $Public.Basename -Variable _PSSlackColorMap Export using wild-cards Export-ModuleMember -Function 'Get-*' Powershell will auto convert array to string with comma Export-ModuleMember -Function @($Public + $Private)) Export-ModuleMember -Function New-GitHubOAuthToken, New-GitHubPullRequest, Get-GitHubIssues, Get-GitHubEvents, Get-GitHubRepositories, ... ...","title":"Export functions"},{"location":"Powershell/Module/#check-if-the-script-is-called-by-dot-source-or-by-module-psm1","text":"# if it's not dot sourced, call the function # Note: $args is an array, in order to pass them to function # need to convert that array to a space separated string if ( $MyInvocation.InvocationName -ne '.' -AND $MyInvocation.Line -ne '' ){ $new_args = $args[1..$($args.Length-1)] -join \" \" Invoke-Expression \"Okto-Login $new_args\" } #Check if it's called by psm1 module if ($MyInvocation.MyCommand.Name.EndsWith('.psm1')){ Export-ModuleMember -Function \"Set-Okto-Login\" }","title":"Check if the script is called by Dot Source or by Module (psm1)"},{"location":"Powershell/PitFalls/","text":"Powershell PitFalls Do not use \"$variable\" to print result Use Write-Debug to debug variable If you use \"$variable\" , it will be \"pushed\" to the return value So if you have function like this function test1 { $a = 1 $a return $False } This function will never return $False because the $a will be part of the return value Suppress output by Out-Null When you run a function, it will by default print out the return value Invoke-Express \"blah_function $args\" | Out-Null Or in the function you don't want to print out, assign to a dummy variable $dummy = $myString -match \"(.*).json\" $fileName = $Matches[1]","title":"Powershell PitFalls"},{"location":"Powershell/PitFalls/#powershell-pitfalls","text":"","title":"Powershell PitFalls"},{"location":"Powershell/PitFalls/#do-not-use-variable-to-print-result","text":"Use Write-Debug to debug variable If you use \"$variable\" , it will be \"pushed\" to the return value So if you have function like this function test1 { $a = 1 $a return $False } This function will never return $False because the $a will be part of the return value","title":"Do not use \"$variable\" to print result"},{"location":"Powershell/PitFalls/#suppress-output-by-out-null","text":"When you run a function, it will by default print out the return value Invoke-Express \"blah_function $args\" | Out-Null Or in the function you don't want to print out, assign to a dummy variable $dummy = $myString -match \"(.*).json\" $fileName = $Matches[1]","title":"Suppress output by Out-Null"},{"location":"Powershell/Snippets/","text":"Common PS Snippets Common PS Snippets Disable/Supress output from function return Select-String Convert between Secure Password and Plain Password Write-Debug, Write-Verbose, Write-Error and Out-String, Out-Null All ConvertFrom-Json create a PSObject, loop its property Create a C# function and populate PSObject in the function Use switch statement Use switch to check PsCmdlet.ParameterSet Use Invoke-RestMethod to get GitHubOAuth Token Use try catch and get the error using $Error[0] Detect 64bit or 32bit then add DLL Use slect (select-object) to add a new property Environment variables Convert From Hashtable To Query String Disable/Supress output from function return Use these ways to avoid print the result after calling a function which returns value [viod]call_function $null = call_function call_function | Out-Null Select-String Perform a case sensitive matching of literal strings: PS C:\\> \"Hello\",\"HELLO\" | select-string -pattern \"HELLO\" -casesensitive Search through all files with the .xml file extension in the current directory and display the lines in those files that include the case sensitive string \"Princess\": PS C:\\> select-string -path *.xml -pattern \"Princess\" -casesensitive Retrieve the last 100 events from the application event log and filter to show only those containing the message string \"failed\": PS C:\\> $events = get-eventlog -logname application -newest 100 PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" Now include 2 lines before and 3 lines after each matching line - line numbers will appear in the output with a > prefixing the matching line: PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" -Context 2,3 Examine all files in the subdirectories of C:\\Windows\\System32 with the .txt file name extension and search for the Case-Sensitive string \"Microsoft\": PS C:\\> get-childitem c:\\windows\\system32\\* -include *.txt -recurse | select-string -pattern \"Microsoft\" -casesensitive Select lines from a file containing \"Total Sales\" and then split the matching lines: PS C:\\> $demo = get-content C:\\demo\\sales.txt PS C:\\> $demo | select-string \"Total Sales\" | %{$_.line.split()} Convert between Secure Password and Plain Password if ($Password) { $BSTR = [System.Runtime.InteropServices.Marshal]::SecureStringToBSTR($Password) $PlainPassword = [System.Runtime.InteropServices.Marshal]::PtrToStringAuto($BSTR) $ConnectionString += \"Password=$PlainPassword;\" } Write-Debug, Write-Verbose, Write-Error and Out-String, Out-Null Write-Debug won't print out anything unless you set $DebugPreference = \"Continue\" That will cause all Write-Debug to print To set it back to defualt $DebugPreference = SilentlyContinue Will stop printing Write-Debug again Try { $conn.Open() } Catch { Write-Error $_ continue } Write-Debug \"ConnectionString $ConnectionString\" Write-Verbose \"Created SQLiteConnection:`n$($Conn | Out-String)\" Out-Null will supress print, useful for some cmdlet which produce unnecessary output New-Item -ItemType directory -Path $APP_SETTING_DIR | Out-Null All ConvertFrom-Json create a PSObject, loop its property PSObject.Properties gets all the Keys (properties), feed to ForEach (%), every item has Name and Value use $_.Name and $_.Value to access all the properties $config_settings = gc $config_file | ConvertFrom-Json Write-Debug $config_settings.alternative_clients $client_options = $config_settings.alternative_clients.PSObject.Properties | ForEach-Object{ $_.Name } $clients_option_string =$client_options -join \",\" Create a C# function and populate PSObject in the function If($As -eq \"PSObject\") { #This code scrubs DBNulls. Props to Dave Wyatt $cSharp = @' using System; using System.Data; using System.Management.Automation; public class DBNullScrubber { public static PSObject DataRowToPSObject(DataRow row) { PSObject psObject = new PSObject(); if (row != null && (row.RowState & DataRowState.Detached) != DataRowState.Detached) { foreach (DataColumn column in row.Table.Columns) { Object value = null; if (!row.IsNull(column)) { value = row[column]; } psObject.Properties.Add(new PSNoteProperty(column.ColumnName, value)); } } return psObject; } } '@ Try { Add-Type -TypeDefinition $cSharp -ReferencedAssemblies 'System.Data','System.Xml' -ErrorAction stop } Catch { If(-not $_.ToString() -like \"*The type name 'DBNullScrubber' already exists*\") { Write-Warning \"Could not load DBNullScrubber. Defaulting to DataRow output: $_\" $As = \"Datarow\" } } } To use the new class and function foreach ($row in $ds.Tables[0].Rows) { [DBNullScrubber]::DataRowToPSObject($row) } Use switch statement First block is a string or Default or a condition block switch ($ErrorActionPreference.tostring()) { {'SilentlyContinue','Ignore' -contains $_} {} 'Stop' { Throw $Err } 'Continue' { Write-Error $Err} Default { Write-Error $Err} } Use switch to check PsCmdlet.ParameterSet Note [string]::IsNullOrEmpty use throw \"Error message\" to throw an error For long lines, use ` to continue lines switch ($PsCmdlet.ParameterSetName) { 'repo' { $missingOwner = [string]::IsNullOrEmpty($Owner) $missingRepo = [string]::IsNullOrEmpty($Repository) if ($missingOwner -and $missingRepo) { $remotes = GetRemotes #first remote in order here wins! 'upstream', 'origin' | % { if ([string]::IsNullOrEmpty($Owner) -and $remotes.$_) { $Owner = $remotes.$_.owner $Repository = $remotes.$_.repository Write-Host \"Found $_ remote with owner $Owner\" } } ... ... throw \"An Owner and Repository must be specified together\" } # accept null or lower case if ($Milestone) { $Milestone = $Milestone.ToLower() } GetRepoIssues $Owner $Repository $Milestone $State.ToLower() ` $Assignee $Creator $Mentioned $Labels $Sort.ToLower() ` $Direction.ToLower() $PsBoundParameters.Since } 'user' { if ([string]::IsNullOrEmpty($Env:GITHUB_OAUTH_TOKEN)) { throw \"Set GITHUB_OAUTH_TOKEN env variable \"} GetUserIssues $Filter.ToLower() $State.ToLower() $Labels ` $Sort.ToLower() $Direction.ToLower() $PsBoundParameters.Since } } Use Invoke-RestMethod to get GitHubOAuth Token it's using basic auth, use GetBytes to convert string to bytes then use ToBase64String to convert them to base64 string function Get-GitHubOAuthTokens { [CmdletBinding()] param( [Parameter(Mandatory = $true)] [string] $UserName, [Parameter(Mandatory = $true)] [string] $Password ) try { $params = @{ Uri = 'https://api.github.com/authorizations'; Headers = @{ Authorization = 'Basic ' + [Convert]::ToBase64String( [Text.Encoding]::ASCII.GetBytes(\"$($userName):$($password)\")); } } $global:GITHUB_API_OUTPUT = Invoke-RestMethod @params #Write-Verbose $global:GITHUB_API_OUTPUT $global:GITHUB_API_OUTPUT | % { $date = [DateTime]::Parse($_.created_at).ToString('g') Write-Host \"`n$($_.app.name) - Created $date\" Write-Host \"`t$($_.token)`n`t$($_.app.url)\" } } catch { Write-Error \"An unexpected error occurred (bad user/password?) $($Error[0])\" } } Use try catch and get the error using $Error[0] catch { Write-Error \"An unexpected error occurred $($Error[0])\" } Detect 64bit or 32bit then add DLL #Pick and import assemblies: if([IntPtr]::size -eq 8) #64 { $SQLiteAssembly = Join-path $PSScriptRoot \"x64\\System.Data.SQLite.dll\" } elseif([IntPtr]::size -eq 4) #32 { $SQLiteAssembly = Join-path $PSScriptRoot \"x86\\System.Data.SQLite.dll\" } else { Throw \"Something is odd with bitness...\" } if( -not ($Library = Add-Type -path $SQLiteAssembly -PassThru -ErrorAction stop) ) { Throw \"This module requires the ADO.NET driver for SQLite:`n`thttp://system.data.sqlite.org/index.html/doc/trunk/www/downloads.wiki\" } Use slect (select-object) to add a new property get-process| select ProcessName, @{ Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} | select -First 4 ProcessName Start Day ----------- --------- AccelerometerSt Sunday AcroRd32 Monday AcroRd32 Monday Adobe CEF Helper Sunday Display only the name, ID and Working Set(WS) properties of Get-Process: PS C:\\> get-process | select-object ProcessName,Id,WS Display only the Name and modules properties of Get-Process, use -ExpandProperty to display the details contained within the modules property: PS C:\\> get-process | select-object ProcessName -expandproperty modules | format-list Display the 5 processes that are using the most memory (WS=Working Set): PS C:\\> get-process | sort-object -property WS | select-object -Last 5 Display the name and claculate the start day of the processes running: PS C:\\> get-process | select-object ProcessName,@{Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} Get the first (newest) and last (oldest) events in the Windows PowerShell event log: PS C:\\> $evts = get-eventlog -log \"Windows PowerShell\" PS C:\\> $evts | select-object -index 0, ($evts.count - 1) Retrieve all the names listed in the Servers.txt file, except for the first one: PS C:\\> get-content servers.txt | select-object -skip 1 Environment variables powershell gci env: # list environment variables dir env: # or gci env: # show env vars whose name contains \u201cpath\u201d Get-ChildItem Env:*path* | format-list # show value of \u201cpath\u201d $env:path Set or Remove # sets a env var named myX for current session $env:myX = \"alice\" # get value of a env var $env:myX # deleting a env var from the current session Remove-Item env:myX # adding path to the path env var $env:path = $env:path + \";C:\\Program Files (x86)\\ErgoEmacs\\hunspell\" View/Set Permament Environment Variables Permanent env vars are stored in Windows Registry. When PowerShell launches, it reads the registry to get the env vars for the current session. However, it does not update the registry whenever you create or remove a env var using the env: provider. To manipulate env var in the registry for permanent use, use the .NET object like the following: View # displaying a env var named \u201cmyY\u201d of the category \u201cUser\u201d. [environment]::GetEnvironmentVariable(\"myY\", \"User\") The possible values for the second argument in GetEnvironmentVariable are: \"Process\", \"User\", \"Machine\". Create, Set # creates \u201cmyY\u201d of category \u201cUser\u201d, and set the value to \u201c\"la la\"\u201d [Environment]::SetEnvironmentVariable(\"myY\", \"la la\", \"User\") Convert From Hashtable To Query String function ConvertFrom-HashtableToQueryString { <# .SYNOPSIS Convert a hashtable into a query string .DESCRIPTION Converts a hashtable into a query string by joining the keys to the values, and then joining all the pairs together .PARAMETER values The hashtable to convert .PARAMETER PairSeparator The string used to concatenate the sets of key=value pairs, defaults to \"&\" .PARAMETER KeyValueSeparator The string used to concatenate the keys to the values, defaults to \"=\" .RETURNVALUE The query string created by joining keys to values and then joining them all together into a single string .EXAMPLE ConvertFrom-HashTable -Values @{ name = 'abcdefg-1' apiProduct = 'Product1' keyExpiresIn = 86400000 } #> PARAM( [Hashtable] $Values, [String] $pairSeparator = '&', [String] $KeyValueSeparator = '=', [string[]]$Sort ) PROCESS { [string]::join($pairSeparator, @( if($Sort) { foreach( $kv in $Values.GetEnumerator() | Sort $Sort) { if($kv.Name) { '{0}{1}{2}' -f $kv.Name, $KeyValueSeparator, $kv.Value } } } else { foreach( $kv in $Values.GetEnumerator()) { if($kv.Name) { '{0}{1}{2}' -f $kv.Name, $KeyValueSeparator, $kv.Value } } } )) }} Get lines and Words counts in a sub-dir using Foreach -Begin -Process -End ls -File -Recurse | % -Begin {$mesure = @{\"Lines\"=0; \"Words\"=0}} -Process { $m = gc $_.FullName | Measure-Object -Line -Word; $mesure[\"Lines\"]+=$m.Lines; $mesure[\"Words\"]+=$m.Words } -End { $mesure }","title":"PS Snippets"},{"location":"Powershell/Snippets/#common-ps-snippets","text":"Common PS Snippets Disable/Supress output from function return Select-String Convert between Secure Password and Plain Password Write-Debug, Write-Verbose, Write-Error and Out-String, Out-Null All ConvertFrom-Json create a PSObject, loop its property Create a C# function and populate PSObject in the function Use switch statement Use switch to check PsCmdlet.ParameterSet Use Invoke-RestMethod to get GitHubOAuth Token Use try catch and get the error using $Error[0] Detect 64bit or 32bit then add DLL Use slect (select-object) to add a new property Environment variables Convert From Hashtable To Query String","title":"Common PS Snippets"},{"location":"Powershell/Snippets/#disablesupress-output-from-function-return","text":"Use these ways to avoid print the result after calling a function which returns value [viod]call_function $null = call_function call_function | Out-Null","title":"Disable/Supress output from function return"},{"location":"Powershell/Snippets/#select-string","text":"Perform a case sensitive matching of literal strings: PS C:\\> \"Hello\",\"HELLO\" | select-string -pattern \"HELLO\" -casesensitive Search through all files with the .xml file extension in the current directory and display the lines in those files that include the case sensitive string \"Princess\": PS C:\\> select-string -path *.xml -pattern \"Princess\" -casesensitive Retrieve the last 100 events from the application event log and filter to show only those containing the message string \"failed\": PS C:\\> $events = get-eventlog -logname application -newest 100 PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" Now include 2 lines before and 3 lines after each matching line - line numbers will appear in the output with a > prefixing the matching line: PS C:\\> $events | select-string -inputobject {$_.message} -pattern \"failed\" -Context 2,3 Examine all files in the subdirectories of C:\\Windows\\System32 with the .txt file name extension and search for the Case-Sensitive string \"Microsoft\": PS C:\\> get-childitem c:\\windows\\system32\\* -include *.txt -recurse | select-string -pattern \"Microsoft\" -casesensitive Select lines from a file containing \"Total Sales\" and then split the matching lines: PS C:\\> $demo = get-content C:\\demo\\sales.txt PS C:\\> $demo | select-string \"Total Sales\" | %{$_.line.split()}","title":"Select-String"},{"location":"Powershell/Snippets/#convert-between-secure-password-and-plain-password","text":"if ($Password) { $BSTR = [System.Runtime.InteropServices.Marshal]::SecureStringToBSTR($Password) $PlainPassword = [System.Runtime.InteropServices.Marshal]::PtrToStringAuto($BSTR) $ConnectionString += \"Password=$PlainPassword;\" }","title":"Convert between Secure Password and Plain Password"},{"location":"Powershell/Snippets/#write-debug-write-verbose-write-error-and-out-string-out-null","text":"Write-Debug won't print out anything unless you set $DebugPreference = \"Continue\" That will cause all Write-Debug to print To set it back to defualt $DebugPreference = SilentlyContinue Will stop printing Write-Debug again Try { $conn.Open() } Catch { Write-Error $_ continue } Write-Debug \"ConnectionString $ConnectionString\" Write-Verbose \"Created SQLiteConnection:`n$($Conn | Out-String)\" Out-Null will supress print, useful for some cmdlet which produce unnecessary output New-Item -ItemType directory -Path $APP_SETTING_DIR | Out-Null","title":"Write-Debug, Write-Verbose, Write-Error and Out-String, Out-Null"},{"location":"Powershell/Snippets/#all-convertfrom-json-create-a-psobject-loop-its-property","text":"PSObject.Properties gets all the Keys (properties), feed to ForEach (%), every item has Name and Value use $_.Name and $_.Value to access all the properties $config_settings = gc $config_file | ConvertFrom-Json Write-Debug $config_settings.alternative_clients $client_options = $config_settings.alternative_clients.PSObject.Properties | ForEach-Object{ $_.Name } $clients_option_string =$client_options -join \",\"","title":"All ConvertFrom-Json create a PSObject, loop its property"},{"location":"Powershell/Snippets/#create-a-c-function-and-populate-psobject-in-the-function","text":"If($As -eq \"PSObject\") { #This code scrubs DBNulls. Props to Dave Wyatt $cSharp = @' using System; using System.Data; using System.Management.Automation; public class DBNullScrubber { public static PSObject DataRowToPSObject(DataRow row) { PSObject psObject = new PSObject(); if (row != null && (row.RowState & DataRowState.Detached) != DataRowState.Detached) { foreach (DataColumn column in row.Table.Columns) { Object value = null; if (!row.IsNull(column)) { value = row[column]; } psObject.Properties.Add(new PSNoteProperty(column.ColumnName, value)); } } return psObject; } } '@ Try { Add-Type -TypeDefinition $cSharp -ReferencedAssemblies 'System.Data','System.Xml' -ErrorAction stop } Catch { If(-not $_.ToString() -like \"*The type name 'DBNullScrubber' already exists*\") { Write-Warning \"Could not load DBNullScrubber. Defaulting to DataRow output: $_\" $As = \"Datarow\" } } } To use the new class and function foreach ($row in $ds.Tables[0].Rows) { [DBNullScrubber]::DataRowToPSObject($row) }","title":"Create a C# function and populate PSObject in the function"},{"location":"Powershell/Snippets/#use-switch-statement","text":"First block is a string or Default or a condition block switch ($ErrorActionPreference.tostring()) { {'SilentlyContinue','Ignore' -contains $_} {} 'Stop' { Throw $Err } 'Continue' { Write-Error $Err} Default { Write-Error $Err} }","title":"Use switch statement"},{"location":"Powershell/Snippets/#use-switch-to-check-pscmdletparameterset","text":"Note [string]::IsNullOrEmpty use throw \"Error message\" to throw an error For long lines, use ` to continue lines switch ($PsCmdlet.ParameterSetName) { 'repo' { $missingOwner = [string]::IsNullOrEmpty($Owner) $missingRepo = [string]::IsNullOrEmpty($Repository) if ($missingOwner -and $missingRepo) { $remotes = GetRemotes #first remote in order here wins! 'upstream', 'origin' | % { if ([string]::IsNullOrEmpty($Owner) -and $remotes.$_) { $Owner = $remotes.$_.owner $Repository = $remotes.$_.repository Write-Host \"Found $_ remote with owner $Owner\" } } ... ... throw \"An Owner and Repository must be specified together\" } # accept null or lower case if ($Milestone) { $Milestone = $Milestone.ToLower() } GetRepoIssues $Owner $Repository $Milestone $State.ToLower() ` $Assignee $Creator $Mentioned $Labels $Sort.ToLower() ` $Direction.ToLower() $PsBoundParameters.Since } 'user' { if ([string]::IsNullOrEmpty($Env:GITHUB_OAUTH_TOKEN)) { throw \"Set GITHUB_OAUTH_TOKEN env variable \"} GetUserIssues $Filter.ToLower() $State.ToLower() $Labels ` $Sort.ToLower() $Direction.ToLower() $PsBoundParameters.Since } }","title":"Use switch to check PsCmdlet.ParameterSet"},{"location":"Powershell/Snippets/#use-invoke-restmethod-to-get-githuboauth-token","text":"it's using basic auth, use GetBytes to convert string to bytes then use ToBase64String to convert them to base64 string function Get-GitHubOAuthTokens { [CmdletBinding()] param( [Parameter(Mandatory = $true)] [string] $UserName, [Parameter(Mandatory = $true)] [string] $Password ) try { $params = @{ Uri = 'https://api.github.com/authorizations'; Headers = @{ Authorization = 'Basic ' + [Convert]::ToBase64String( [Text.Encoding]::ASCII.GetBytes(\"$($userName):$($password)\")); } } $global:GITHUB_API_OUTPUT = Invoke-RestMethod @params #Write-Verbose $global:GITHUB_API_OUTPUT $global:GITHUB_API_OUTPUT | % { $date = [DateTime]::Parse($_.created_at).ToString('g') Write-Host \"`n$($_.app.name) - Created $date\" Write-Host \"`t$($_.token)`n`t$($_.app.url)\" } } catch { Write-Error \"An unexpected error occurred (bad user/password?) $($Error[0])\" } }","title":"Use Invoke-RestMethod to get GitHubOAuth Token"},{"location":"Powershell/Snippets/#use-try-catch-and-get-the-error-using-error0","text":"catch { Write-Error \"An unexpected error occurred $($Error[0])\" }","title":"Use try catch and get the error using $Error[0]"},{"location":"Powershell/Snippets/#detect-64bit-or-32bit-then-add-dll","text":"#Pick and import assemblies: if([IntPtr]::size -eq 8) #64 { $SQLiteAssembly = Join-path $PSScriptRoot \"x64\\System.Data.SQLite.dll\" } elseif([IntPtr]::size -eq 4) #32 { $SQLiteAssembly = Join-path $PSScriptRoot \"x86\\System.Data.SQLite.dll\" } else { Throw \"Something is odd with bitness...\" } if( -not ($Library = Add-Type -path $SQLiteAssembly -PassThru -ErrorAction stop) ) { Throw \"This module requires the ADO.NET driver for SQLite:`n`thttp://system.data.sqlite.org/index.html/doc/trunk/www/downloads.wiki\" }","title":"Detect 64bit or 32bit then add DLL"},{"location":"Powershell/Snippets/#use-slect-select-object-to-add-a-new-property","text":"get-process| select ProcessName, @{ Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} | select -First 4 ProcessName Start Day ----------- --------- AccelerometerSt Sunday AcroRd32 Monday AcroRd32 Monday Adobe CEF Helper Sunday Display only the name, ID and Working Set(WS) properties of Get-Process: PS C:\\> get-process | select-object ProcessName,Id,WS Display only the Name and modules properties of Get-Process, use -ExpandProperty to display the details contained within the modules property: PS C:\\> get-process | select-object ProcessName -expandproperty modules | format-list Display the 5 processes that are using the most memory (WS=Working Set): PS C:\\> get-process | sort-object -property WS | select-object -Last 5 Display the name and claculate the start day of the processes running: PS C:\\> get-process | select-object ProcessName,@{Name=\"Start Day\"; Expression={$_.StartTime.DayOfWeek}} Get the first (newest) and last (oldest) events in the Windows PowerShell event log: PS C:\\> $evts = get-eventlog -log \"Windows PowerShell\" PS C:\\> $evts | select-object -index 0, ($evts.count - 1) Retrieve all the names listed in the Servers.txt file, except for the first one: PS C:\\> get-content servers.txt | select-object -skip 1","title":"Use slect (select-object) to add a new property"},{"location":"Powershell/Snippets/#environment-variables","text":"powershell gci env: # list environment variables dir env: # or gci env: # show env vars whose name contains \u201cpath\u201d Get-ChildItem Env:*path* | format-list # show value of \u201cpath\u201d $env:path Set or Remove # sets a env var named myX for current session $env:myX = \"alice\" # get value of a env var $env:myX # deleting a env var from the current session Remove-Item env:myX # adding path to the path env var $env:path = $env:path + \";C:\\Program Files (x86)\\ErgoEmacs\\hunspell\" View/Set Permament Environment Variables Permanent env vars are stored in Windows Registry. When PowerShell launches, it reads the registry to get the env vars for the current session. However, it does not update the registry whenever you create or remove a env var using the env: provider. To manipulate env var in the registry for permanent use, use the .NET object like the following: View # displaying a env var named \u201cmyY\u201d of the category \u201cUser\u201d. [environment]::GetEnvironmentVariable(\"myY\", \"User\") The possible values for the second argument in GetEnvironmentVariable are: \"Process\", \"User\", \"Machine\". Create, Set # creates \u201cmyY\u201d of category \u201cUser\u201d, and set the value to \u201c\"la la\"\u201d [Environment]::SetEnvironmentVariable(\"myY\", \"la la\", \"User\")","title":"Environment variables"},{"location":"Powershell/Snippets/#convert-from-hashtable-to-query-string","text":"function ConvertFrom-HashtableToQueryString { <# .SYNOPSIS Convert a hashtable into a query string .DESCRIPTION Converts a hashtable into a query string by joining the keys to the values, and then joining all the pairs together .PARAMETER values The hashtable to convert .PARAMETER PairSeparator The string used to concatenate the sets of key=value pairs, defaults to \"&\" .PARAMETER KeyValueSeparator The string used to concatenate the keys to the values, defaults to \"=\" .RETURNVALUE The query string created by joining keys to values and then joining them all together into a single string .EXAMPLE ConvertFrom-HashTable -Values @{ name = 'abcdefg-1' apiProduct = 'Product1' keyExpiresIn = 86400000 } #> PARAM( [Hashtable] $Values, [String] $pairSeparator = '&', [String] $KeyValueSeparator = '=', [string[]]$Sort ) PROCESS { [string]::join($pairSeparator, @( if($Sort) { foreach( $kv in $Values.GetEnumerator() | Sort $Sort) { if($kv.Name) { '{0}{1}{2}' -f $kv.Name, $KeyValueSeparator, $kv.Value } } } else { foreach( $kv in $Values.GetEnumerator()) { if($kv.Name) { '{0}{1}{2}' -f $kv.Name, $KeyValueSeparator, $kv.Value } } } )) }}","title":"Convert From Hashtable To Query String"},{"location":"Powershell/Snippets/#get-lines-and-words-counts-in-a-sub-dir-using-foreach-begin-process-end","text":"ls -File -Recurse | % -Begin {$mesure = @{\"Lines\"=0; \"Words\"=0}} -Process { $m = gc $_.FullName | Measure-Object -Line -Word; $mesure[\"Lines\"]+=$m.Lines; $mesure[\"Words\"]+=$m.Words } -End { $mesure }","title":"Get lines and Words counts in a sub-dir using Foreach -Begin -Process -End"},{"location":"Powershell/Utility/","text":"Utility snippet function Write-InfoLog($content) { Write-Host \"$(Get-Date -Format {yyyy-MM-dd hh:mm:ss.fff}) | INFO | $content\" -foregroundcolor \"Green\" } function Write-DebugLog($content) { Write-Debug \"$(Get-Date -Format {yyyy-MM-dd hh:mm:ss.fff}) | DEBUG | $content\" } function Invoke-ExternalProgram($program, $arguments, $workingDir) { $command = \"[${program} ${arguments}]\" Write-InfoLog \"running external program ${command}\" $process = Start-Process $program -wait -NoNewWindow -PassThru -ArgumentList $arguments -WorkingDirectory $workingDir if ($process.ExitCode -ne 0) { throw \"error while running external program ${command}\" } } function Invoke-Replace($file, $target, $value) { (Get-Content $file).replace($target, $value) | Set-Content $file } function New-Directory($path) { if (Test-Path $path) { Remove-item -Path $path -Recurse | Out-Null } New-Item -Path $path -ItemType directory | Out-Null } function New-File($directory, $name, $value) { New-Item -Force -Path $directory -Name $name -ItemType file -Value $value | Out-Null } function Get-Directories($dirPath) { return $dirPath.Split(\"/\") } function Get-RelativePath($target, $base) { if ($base -eq $null) { return Get-Item $target | Resolve-Path -Relative } else { $current = Get-Location Set-Location $base $relativePath = Get-Item $target | Resolve-Path -Relative Set-Location $current return $relativePath } } function Get-Json($path) { return (Get-Content -Raw -Path $path | ConvertFrom-Json) }","title":"PS Utility Note"},{"location":"Powershell/Utility/#utility-snippet","text":"function Write-InfoLog($content) { Write-Host \"$(Get-Date -Format {yyyy-MM-dd hh:mm:ss.fff}) | INFO | $content\" -foregroundcolor \"Green\" } function Write-DebugLog($content) { Write-Debug \"$(Get-Date -Format {yyyy-MM-dd hh:mm:ss.fff}) | DEBUG | $content\" } function Invoke-ExternalProgram($program, $arguments, $workingDir) { $command = \"[${program} ${arguments}]\" Write-InfoLog \"running external program ${command}\" $process = Start-Process $program -wait -NoNewWindow -PassThru -ArgumentList $arguments -WorkingDirectory $workingDir if ($process.ExitCode -ne 0) { throw \"error while running external program ${command}\" } } function Invoke-Replace($file, $target, $value) { (Get-Content $file).replace($target, $value) | Set-Content $file } function New-Directory($path) { if (Test-Path $path) { Remove-item -Path $path -Recurse | Out-Null } New-Item -Path $path -ItemType directory | Out-Null } function New-File($directory, $name, $value) { New-Item -Force -Path $directory -Name $name -ItemType file -Value $value | Out-Null } function Get-Directories($dirPath) { return $dirPath.Split(\"/\") } function Get-RelativePath($target, $base) { if ($base -eq $null) { return Get-Item $target | Resolve-Path -Relative } else { $current = Get-Location Set-Location $base $relativePath = Get-Item $target | Resolve-Path -Relative Set-Location $current return $relativePath } } function Get-Json($path) { return (Get-Content -Raw -Path $path | ConvertFrom-Json) }","title":"Utility snippet"}]}